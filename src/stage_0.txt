
🔍 Loading model and tokenizer for 'Pavankalyan/stages_0_model'...

🔢 Parameter Breakdown
----------------------
Embedding parameters:     51,465,216
Non-embedding parameters: 134,235,136
Total parameters:         185,700,352

⚙️ Model Config Info
--------------------
Model class: LlamaModel
Architectures: ['LlamaForCausalLM']
Hidden size: 1024
Intermediate size: 4096
Num hidden layers: 8
Num attention heads: 16
Max position embeddings: 2048
Tied embeddings: True
Is encoder: False
Is decoder-only: False

🔤 Tokenizer Info
-----------------
Tokenizer class: GPT2TokenizerFast
Vocab size: 50,257
Special tokens:
  pad_token   : None
  bos_token   : '<|endoftext|>'
  eos_token   : '<|endoftext|>'
  unk_token   : '<|endoftext|>'
  cls_token   : None
  sep_token   : None
  mask_token  : None
