{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3d03d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datadrive/pavan/anaconda3/envs/gemma_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38118e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3871013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/datadrive/pavan/CurLL/src/data/stage0_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677b068d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    3275181\n",
       "val        42540\n",
       "test        2610\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53cb1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df['split']=='val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f6b4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['split']=='test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c09a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context_template\n",
       "Repeat back instructions        903\n",
       "Describe what happened          903\n",
       "Continue the story              903\n",
       "Follow simple directions        903\n",
       "Explain the action              903\n",
       "Mimic the sound                 903\n",
       "Predict what's next             903\n",
       "Respond to question             903\n",
       "Confirm understanding           903\n",
       "Re-tell the sequence            903\n",
       "Action demonstration request    903\n",
       "Imitate observed behavior       903\n",
       "Describe common features        903\n",
       "Identify differences            903\n",
       "Expand on statement             903\n",
       "Explain feelings                903\n",
       "Simple cause effect             903\n",
       "Answer yes or no                903\n",
       "Identify missing piece          903\n",
       "What comes before?              903\n",
       "What comes after?               903\n",
       "Extend the idea                 903\n",
       "Describe the problem            903\n",
       "Ask clarifying question         903\n",
       "Respond to greeting             903\n",
       "Echo the phrase                 903\n",
       "Extend the conversation         903\n",
       "React to statement              903\n",
       "Simple role-play                903\n",
       "Give simple definition          903\n",
       "Respond to prompt               903\n",
       "Provide simple context          903\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['id']=='i1']['context_template'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4f96752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context_template\n",
       "Repeat back instructions    88\n",
       "Identify missing piece      50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['id']=='i1']['context_template'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2b6b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>id</th>\n",
       "      <th>indicator</th>\n",
       "      <th>skill</th>\n",
       "      <th>subskill</th>\n",
       "      <th>goal</th>\n",
       "      <th>age_group</th>\n",
       "      <th>stage</th>\n",
       "      <th>context_template</th>\n",
       "      <th>word_list</th>\n",
       "      <th>instruction</th>\n",
       "      <th>response</th>\n",
       "      <th>POS</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23465</th>\n",
       "      <td>{'instruction': 'Okay, Leo, I want you to tell...</td>\n",
       "      <td>i1</td>\n",
       "      <td>Shows ongoing connection to a conversation, gr...</td>\n",
       "      <td>Language and Communication</td>\n",
       "      <td>Attending and Understanding</td>\n",
       "      <td>Child attends to communication and language fr...</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Repeat back instructions</td>\n",
       "      <td>rest</td>\n",
       "      <td>Okay, Leo, I want you to tell me what I just a...</td>\n",
       "      <td>You want me to say what you said? You wanted m...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23469</th>\n",
       "      <td>{'instruction': \"Okay, Leo, I'm going to tell ...</td>\n",
       "      <td>i1</td>\n",
       "      <td>Shows ongoing connection to a conversation, gr...</td>\n",
       "      <td>Language and Communication</td>\n",
       "      <td>Attending and Understanding</td>\n",
       "      <td>Child attends to communication and language fr...</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Repeat back instructions</td>\n",
       "      <td>rinse</td>\n",
       "      <td>Okay, Leo, I'm going to tell you what we need ...</td>\n",
       "      <td>Rinse our hands! We have to rinse our hands wi...</td>\n",
       "      <td>Verb</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23472</th>\n",
       "      <td>{'instruction': 'Okay, so I want you to tell m...</td>\n",
       "      <td>i1</td>\n",
       "      <td>Shows ongoing connection to a conversation, gr...</td>\n",
       "      <td>Language and Communication</td>\n",
       "      <td>Attending and Understanding</td>\n",
       "      <td>Child attends to communication and language fr...</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Repeat back instructions</td>\n",
       "      <td>reach</td>\n",
       "      <td>Okay, so I want you to tell me what I just ask...</td>\n",
       "      <td>You want me to...to tell you what you said! Yo...</td>\n",
       "      <td>Verb</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>{'instruction': \"Okay, Leo, I'm going to tell ...</td>\n",
       "      <td>i1</td>\n",
       "      <td>Shows ongoing connection to a conversation, gr...</td>\n",
       "      <td>Language and Communication</td>\n",
       "      <td>Attending and Understanding</td>\n",
       "      <td>Child attends to communication and language fr...</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Repeat back instructions</td>\n",
       "      <td>rule</td>\n",
       "      <td>Okay, Leo, I'm going to tell you something imp...</td>\n",
       "      <td>Put the blocks back in the bin... that's the r...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23494</th>\n",
       "      <td>{'instruction': 'Okay, so I want you to tell m...</td>\n",
       "      <td>i1</td>\n",
       "      <td>Shows ongoing connection to a conversation, gr...</td>\n",
       "      <td>Language and Communication</td>\n",
       "      <td>Attending and Understanding</td>\n",
       "      <td>Child attends to communication and language fr...</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Repeat back instructions</td>\n",
       "      <td>pretzel</td>\n",
       "      <td>Okay, so I want you to tell me what I just ask...</td>\n",
       "      <td>Um... you want me to tell you what you said? Y...</td>\n",
       "      <td>Noun</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  output  id  \\\n",
       "23465  {'instruction': 'Okay, Leo, I want you to tell...  i1   \n",
       "23469  {'instruction': \"Okay, Leo, I'm going to tell ...  i1   \n",
       "23472  {'instruction': 'Okay, so I want you to tell m...  i1   \n",
       "23480  {'instruction': \"Okay, Leo, I'm going to tell ...  i1   \n",
       "23494  {'instruction': 'Okay, so I want you to tell m...  i1   \n",
       "\n",
       "                                               indicator  \\\n",
       "23465  Shows ongoing connection to a conversation, gr...   \n",
       "23469  Shows ongoing connection to a conversation, gr...   \n",
       "23472  Shows ongoing connection to a conversation, gr...   \n",
       "23480  Shows ongoing connection to a conversation, gr...   \n",
       "23494  Shows ongoing connection to a conversation, gr...   \n",
       "\n",
       "                            skill                     subskill  \\\n",
       "23465  Language and Communication  Attending and Understanding   \n",
       "23469  Language and Communication  Attending and Understanding   \n",
       "23472  Language and Communication  Attending and Understanding   \n",
       "23480  Language and Communication  Attending and Understanding   \n",
       "23494  Language and Communication  Attending and Understanding   \n",
       "\n",
       "                                                    goal age_group  stage  \\\n",
       "23465  Child attends to communication and language fr...       0-5      0   \n",
       "23469  Child attends to communication and language fr...       0-5      0   \n",
       "23472  Child attends to communication and language fr...       0-5      0   \n",
       "23480  Child attends to communication and language fr...       0-5      0   \n",
       "23494  Child attends to communication and language fr...       0-5      0   \n",
       "\n",
       "               context_template word_list  \\\n",
       "23465  Repeat back instructions      rest   \n",
       "23469  Repeat back instructions     rinse   \n",
       "23472  Repeat back instructions     reach   \n",
       "23480  Repeat back instructions      rule   \n",
       "23494  Repeat back instructions   pretzel   \n",
       "\n",
       "                                             instruction  \\\n",
       "23465  Okay, Leo, I want you to tell me what I just a...   \n",
       "23469  Okay, Leo, I'm going to tell you what we need ...   \n",
       "23472  Okay, so I want you to tell me what I just ask...   \n",
       "23480  Okay, Leo, I'm going to tell you something imp...   \n",
       "23494  Okay, so I want you to tell me what I just ask...   \n",
       "\n",
       "                                                response   POS split  \n",
       "23465  You want me to say what you said? You wanted m...  Noun  test  \n",
       "23469  Rinse our hands! We have to rinse our hands wi...  Verb  test  \n",
       "23472  You want me to...to tell you what you said! Yo...  Verb  test  \n",
       "23480  Put the blocks back in the bin... that's the r...  Noun  test  \n",
       "23494  Um... you want me to tell you what you said? Y...  Noun  test  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['id']=='i1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48b8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_stage(stage):\n",
    "    ds = load_dataset(f\"Pavankalyan/stage{stage}_instruct_cleaned\")\n",
    "    df = ds['train'].to_pandas()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c8b5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 0\n",
    "df = get_dataframe_stage(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec10763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:48: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/datadrive/pavan/tmp/ipykernel_1711679/1132740496.py:48: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def compute_distance(embeddings, A, B):\n",
    "    return cosine_distances(embeddings[A], embeddings[B]).mean()\n",
    "\n",
    "def relative_distance_zscores(embeddings, selected, Z_indices, num_samples=1000):\n",
    "    all_indices = set(range(len(embeddings)))\n",
    "    selected_set = set(selected)\n",
    "    Z_set = set(Z_indices)\n",
    "\n",
    "    complement_Y = list(all_indices - selected_set)\n",
    "    complement_Z = list(Z_set - selected_set)\n",
    "    nonZ = list(all_indices - Z_set)\n",
    "\n",
    "    x = len(selected)\n",
    "    Z_pool = list(Z_set - selected_set)\n",
    "\n",
    "    def sample_random_subsets(pool):\n",
    "        return [random.sample(pool, x) for _ in range(num_samples)]\n",
    "\n",
    "    def compute_distribution(target_fn):\n",
    "        scores = [target_fn(s) for s in sample_random_subsets(Z_indices)]\n",
    "        mu = np.mean(scores)\n",
    "        sigma = np.std(scores)\n",
    "        return mu, sigma\n",
    "\n",
    "    def get_z(actual, mu, sigma):\n",
    "        return (actual - mu) / sigma if sigma > 0 else float('nan')\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # D1: to Y - selected\n",
    "    actual_D1 = compute_distance(embeddings, selected, list(all_indices - set(selected)))\n",
    "    mu1, sigma1 = compute_distribution(lambda s: compute_distance(embeddings, s, list(all_indices - set(s))))\n",
    "    results[\"D1 (to Y-Zₓ)\"] = (actual_D1, mu1, sigma1, get_z(actual_D1, mu1, sigma1))\n",
    "\n",
    "    # D2: to Z - selected\n",
    "    actual_D2 = compute_distance(embeddings, selected, list(Z_set - selected_set)) if len(complement_Z) > 0 else float('nan')\n",
    "    mu2, sigma2 = compute_distribution(lambda s: compute_distance(embeddings, s, list(Z_set - set(s))))\n",
    "    results[\"D2 (to Z-Zₓ)\"] = (actual_D2, mu2, sigma2, get_z(actual_D2, mu2, sigma2))\n",
    "\n",
    "    # D3: to Y - Z\n",
    "    actual_D3 = compute_distance(embeddings, selected, list(nonZ))\n",
    "    mu3, sigma3 = compute_distribution(lambda s: compute_distance(embeddings, s, list(nonZ)))\n",
    "    results[\"D3 (to Y-Z)\"] = (actual_D3, mu3, sigma3, get_z(actual_D3, mu3, sigma3))\n",
    "\n",
    "    return results\n",
    "    \n",
    "def find_diverse_subset_from_Z(Y, Z_indices, x, num_samples=1000):\n",
    "    \"\"\"\n",
    "    From list Y, and subset Z_indices, select x elements from Z that are maximally different from Y \\ selected_x.\n",
    "    \n",
    "    Returns:\n",
    "        best_indices: indices (in Y) of x elements from Z that are most different.\n",
    "        raw_score: average distance of best_indices to Y \\ best_indices.\n",
    "        relative_score: z-score compared to random x-subsets of Z.\n",
    "    \"\"\"\n",
    "    assert x <= len(Z_indices), \"x must be <= size of Z\"\n",
    "    assert x < len(Y), \"x must be < total size of Y\"\n",
    "\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embeddings = model.encode(Y, normalize_embeddings=True)\n",
    "    dist_matrix = cosine_distances(embeddings)\n",
    "\n",
    "    # Step 1: Greedy selection from Z_indices\n",
    "    selected = []\n",
    "    candidates = list(Z_indices)\n",
    "    Y_indices = set(range(len(Y)))\n",
    "\n",
    "    for _ in range(x):\n",
    "        best_idx = None\n",
    "        best_score = -np.inf\n",
    "\n",
    "        for idx in candidates:\n",
    "            temp_selected = selected + [idx]\n",
    "            temp_rest = list(Y_indices - set(temp_selected))\n",
    "            avg_dist = dist_matrix[np.ix_(temp_selected, temp_rest)].mean()\n",
    "            if avg_dist > best_score:\n",
    "                best_score = avg_dist\n",
    "                best_idx = idx\n",
    "\n",
    "        selected.append(best_idx)\n",
    "        candidates.remove(best_idx)\n",
    "\n",
    "    results = relative_distance_zscores(embeddings, selected, Z_indices)\n",
    "\n",
    "    return selected, results, embeddings\n",
    "\n",
    "\n",
    "def plot_tsne(embeddings, selected, Z_indices, Y):\n",
    "    tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "    reduced = tsne.fit_transform(embeddings)\n",
    "\n",
    "    all_indices = set(range(len(Y)))\n",
    "    Z_set = set(Z_indices)\n",
    "    selected_set = set(selected)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(len(Y)):\n",
    "        if i in selected_set:\n",
    "            plt.scatter(*reduced[i], color='red', label='Zₓ (Selected)' if 'Zₓ' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "        elif i in Z_set:\n",
    "            plt.scatter(*reduced[i], color='blue', alpha=0.5, label='Z - Zₓ' if 'Z - Zₓ' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "        else:\n",
    "            plt.scatter(*reduced[i], color='gray', alpha=0.3, label='Y - Z' if 'Y - Z' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "    plt.title(\"t-SNE of Topic Embeddings\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_test_templates(df, id, num_templates, num_indi):\n",
    "    topics = list(df['context_template'].unique())\n",
    "    Z_topics = list(set(df[df['id']==id]['context_template'].values))\n",
    "    Z_indices = [topics.index(t) for t in Z_topics]\n",
    "    selected_ids, results, embeddings = find_diverse_subset_from_Z(topics, Z_indices, x=num_templates)\n",
    "    selected_topics = [topics[i] for i in selected_ids]\n",
    "    results_dict = {}\n",
    "    for name, (actual, mu, sigma, z) in results.items():\n",
    "        results_dict[name] = {\n",
    "            \"actual\": actual,\n",
    "            \"mu\": mu,\n",
    "            \"sigma\": sigma,\n",
    "            \"z\": z\n",
    "        }\n",
    "    results_dict[\"selected_topics\"] =  selected_topics\n",
    "    all_inds = list(df['indicator'].unique())\n",
    "    main_ind = df[df['id']==id]['indicator'].values[0]\n",
    "    index_ind = all_inds.index(main_ind)\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embeddings_inds = model.encode(all_inds, normalize_embeddings=True)\n",
    "    dist_matrix = cosine_distances(embeddings_inds)\n",
    "    distances = dist_matrix[index_ind]\n",
    "    closest_indices = np.argsort(distances)\n",
    "    closest_indices = closest_indices[closest_indices != index_ind][:num_indi]\n",
    "    closest_elements = [all_inds[j] for j in closest_indices]\n",
    "    closest_ids = [df[df['indicator']==closest_elements[j]]['id'].values[0] for j in range(len(closest_elements))]\n",
    "    results_dict[\"closest_indicators\"] = closest_elements\n",
    "    results_dict[\"closest_indicators_distances\"] = distances[closest_indices]\n",
    "    results_dict[\"closest_indicators_ids\"] = closest_ids\n",
    "    return results_dict\n",
    "\n",
    "def make_json_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: make_json_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_json_serializable(i) for i in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64, np.int32, np.int64)):\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc15ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = make_json_serializable(get_test_templates(df, id=\"i0\", num_templates=2, num_indi=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c4ca11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_instruction_response(example):\n",
    "    return example[\"instruction\"] + \"\\n\\n\" + example[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99558011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split'] = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c794c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"i0\"\n",
    "tempdf1 = df[df['id'] == id].reset_index(drop=True)\n",
    "tempdf2 = df[\n",
    "        (df['id'] == res['closest_indicators_ids'][0]) |\n",
    "        (df['id'] == res['closest_indicators_ids'][1])\n",
    "    ].reset_index(drop=True)\n",
    "tempdf1['ir_output'] = tempdf1.apply(concat_instruction_response, axis=1)\n",
    "tempdf2['ir_output'] = tempdf2.apply(concat_instruction_response, axis=1)\n",
    "tempdf = pd.concat([tempdf1, tempdf2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6db83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_topic = res['selected_topics'][0]\n",
    "tempdf_t = tempdf1[tempdf1['context_template'] == sel_topic].reset_index(drop=True)\n",
    "main_irs = tempdf_t['ir_output'].tolist()\n",
    "all_irs = tempdf['ir_output'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c089220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_indices = [all_irs.index(m) for m in main_irs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc56d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a1e96f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1694/1694 [00:16<00:00, 99.67it/s] \n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(all_irs, normalize_embeddings=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37605e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = cosine_distances(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1003a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Greedy selection from Z_indices\n",
    "selected = []\n",
    "candidates = list(Z_indices)\n",
    "Y_indices = set(range(len(all_irs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52206c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "538515b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:51<00:00,  5.84s/it]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(num_test_samples)):\n",
    "    best_idx = None\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for idx in candidates:\n",
    "        temp_selected = selected + [idx]\n",
    "        temp_rest = list(Y_indices - set(temp_selected))\n",
    "        avg_dist = dist_matrix[np.ix_(temp_selected, temp_rest)].mean()\n",
    "        if avg_dist > best_score:\n",
    "            best_score = avg_dist\n",
    "            best_idx = idx\n",
    "\n",
    "    selected.append(best_idx)\n",
    "    candidates.remove(best_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dc6aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = tempdf.iloc[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7128f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(selected_rows.index):\n",
    "    row = tempdf.loc[idx]\n",
    "    df.loc[\n",
    "        (df['id'] == id) &\n",
    "        (df['context_template'] == sel_topic) &\n",
    "        (df['instruction'] == row['instruction']),\n",
    "        'split'\n",
    "    ] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34d82a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for all matching rows\n",
    "mask = (\n",
    "    df['id'] == id\n",
    ") & (\n",
    "    df['context_template'] == sel_topic\n",
    ") & (\n",
    "    df['instruction'].isin(tempdf.loc[selected_rows.index, 'instruction'])\n",
    ")\n",
    "\n",
    "# Assign 'val' to the 'split' column for the matching rows\n",
    "df.loc[mask, 'split'] = 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1fcf70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_rows = tempdf.drop(selected_rows.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b236c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for all matching rows\n",
    "mask = (\n",
    "    df['id'] == id\n",
    ") & (\n",
    "    df['context_template'] == sel_topic\n",
    ") & (\n",
    "    df['instruction'].isin(tempdf.loc[remaining_rows.index, 'instruction'])\n",
    ")\n",
    "\n",
    "# Assign 'val' to the 'split' column for the matching rows\n",
    "df.loc[mask, 'split'] = 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "791bb635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    3319428\n",
       "val          853\n",
       "test          50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = list(df['id'].unique())\n",
    "all_results = []\n",
    "for i in tqdm(range(len(all_ids))):\n",
    "    res = get_test_templates(df, id=all_ids[i], num_templates=2, num_indi=2)\n",
    "    all_results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbbf7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results as jsonl\n",
    "import json\n",
    "with open(f\"/datadrive/pavan/CurLL/data/stage{stage}_test_topics.jsonl\", \"w\") as f:\n",
    "    json.dump(all_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdf630d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_texts(texts, model, batch_size=64):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        emb = model.encode(batch, convert_to_tensor=True, normalize_embeddings=True)\n",
    "        embeddings.append(emb)\n",
    "    return torch.cat(embeddings, dim=0)  # Shape: (N, D)\n",
    "\n",
    "def compute_distance_torch(embeddings, A, B):\n",
    "    A_emb = embeddings[A]\n",
    "    B_emb = embeddings[B]\n",
    "    sim = torch.nn.functional.cosine_similarity(\n",
    "        A_emb.unsqueeze(1), B_emb.unsqueeze(0), dim=2\n",
    "    )\n",
    "    return (1 - sim).mean().item()\n",
    "\n",
    "def relative_distance_zscores_torch(embeddings, selected, Z_indices, num_samples=1000):\n",
    "    N = embeddings.shape[0]\n",
    "    all_indices = set(range(N))\n",
    "    selected_set = set(selected)\n",
    "    Z_set = set(Z_indices)\n",
    "\n",
    "    complement_Y = list(all_indices - selected_set)\n",
    "    complement_Z = list(Z_set - selected_set)\n",
    "    nonZ = list(all_indices - Z_set)\n",
    "    x = len(selected)\n",
    "\n",
    "    def sample_random_subsets(pool):\n",
    "        return [random.sample(pool, x) for _ in range(num_samples)]\n",
    "\n",
    "    def compute_distribution(target_fn, pool):\n",
    "        samples = sample_random_subsets(pool)\n",
    "        scores = [target_fn(s) for s in samples]\n",
    "        mu, sigma = np.mean(scores), np.std(scores)\n",
    "        return mu, sigma\n",
    "\n",
    "    def get_z(actual, mu, sigma):\n",
    "        return (actual - mu) / sigma if sigma > 0 else float('nan')\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    actual_D1 = compute_distance_torch(embeddings, selected, complement_Y)\n",
    "    mu1, sigma1 = compute_distribution(lambda s: compute_distance_torch(embeddings, s, list(all_indices - set(s))), Z_indices)\n",
    "    results[\"D1 (to Y-Zₓ)\"] = (actual_D1, mu1, sigma1, get_z(actual_D1, mu1, sigma1))\n",
    "\n",
    "    if len(complement_Z) > 0:\n",
    "        actual_D2 = compute_distance_torch(embeddings, selected, complement_Z)\n",
    "        mu2, sigma2 = compute_distribution(lambda s: compute_distance_torch(embeddings, s, list(Z_set - set(s))), Z_indices)\n",
    "    else:\n",
    "        actual_D2, mu2, sigma2 = float('nan'), float('nan'), float('nan')\n",
    "    results[\"D2 (to Z-Zₓ)\"] = (actual_D2, mu2, sigma2, get_z(actual_D2, mu2, sigma2))\n",
    "\n",
    "    actual_D3 = compute_distance_torch(embeddings, selected, nonZ)\n",
    "    mu3, sigma3 = compute_distribution(lambda s: compute_distance_torch(embeddings, s, nonZ), Z_indices)\n",
    "    results[\"D3 (to Y-Z)\"] = (actual_D3, mu3, sigma3, get_z(actual_D3, mu3, sigma3))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def find_diverse_subset_from_Z(Y, Z_indices, x, num_samples=1000):\n",
    "    assert x <= len(Z_indices), \"x must be <= size of Z\"\n",
    "    assert x < len(Y), \"x must be < total size of Y\"\n",
    "\n",
    "    # GPU-accelerated SentenceTransformer\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cuda')\n",
    "    embeddings = encode_texts(Y, model)\n",
    "\n",
    "    N = embeddings.shape[0]\n",
    "    dist_matrix = 1 - torch.matmul(embeddings, embeddings.T)  # cosine distance matrix\n",
    "\n",
    "    selected = []\n",
    "    candidates = list(Z_indices)\n",
    "    Y_indices = set(range(N))\n",
    "\n",
    "    for _ in range(x):\n",
    "        best_score, best_idx = -1, None\n",
    "        for idx in candidates:\n",
    "            temp_selected = selected + [idx]\n",
    "            temp_rest = list(Y_indices - set(temp_selected))\n",
    "            avg_dist = dist_matrix[temp_selected][:, temp_rest].mean().item()\n",
    "            if avg_dist > best_score:\n",
    "                best_score, best_idx = avg_dist, idx\n",
    "        selected.append(best_idx)\n",
    "        candidates.remove(best_idx)\n",
    "\n",
    "    results = relative_distance_zscores_torch(embeddings, selected, Z_indices, num_samples)\n",
    "    return selected, results, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/182 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/182 [05:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m t3 = time.perf_counter()\n\u001b[32m     32\u001b[39m Z_indices = [all_irs.index(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m main_irs]\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m selected_ids, results, embeddings = \u001b[43mfind_diverse_subset_from_Z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_irs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m selected_rows = tempdf_t.iloc[selected_ids]\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# update split\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gemma_env/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mfind_diverse_subset_from_Z\u001b[39m\u001b[34m(Y, Z_indices, x, num_samples)\u001b[39m\n\u001b[32m     90\u001b[39m     selected.append(best_idx)\n\u001b[32m     91\u001b[39m     candidates.remove(best_idx)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m results = \u001b[43mrelative_distance_zscores_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m selected, results, embeddings\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mrelative_distance_zscores_torch\u001b[39m\u001b[34m(embeddings, selected, Z_indices, num_samples)\u001b[39m\n\u001b[32m     57\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mD2 (to Z-Zₓ)\u001b[39m\u001b[33m\"\u001b[39m] = (actual_D2, mu2, sigma2, get_z(actual_D2, mu2, sigma2))\n\u001b[32m     59\u001b[39m actual_D3 = compute_distance_torch(embeddings, selected, nonZ)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m mu3, sigma3 = \u001b[43mcompute_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_distance_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonZ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mD3 (to Y-Z)\u001b[39m\u001b[33m\"\u001b[39m] = (actual_D3, mu3, sigma3, get_z(actual_D3, mu3, sigma3))\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mrelative_distance_zscores_torch.<locals>.compute_distribution\u001b[39m\u001b[34m(target_fn, pool)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_distribution\u001b[39m(target_fn, pool):\n\u001b[32m     38\u001b[39m     samples = sample_random_subsets(pool)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     scores = [\u001b[43mtarget_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[32m     40\u001b[39m     mu, sigma = np.mean(scores), np.std(scores)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mu, sigma\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mrelative_distance_zscores_torch.<locals>.<lambda>\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m     57\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mD2 (to Z-Zₓ)\u001b[39m\u001b[33m\"\u001b[39m] = (actual_D2, mu2, sigma2, get_z(actual_D2, mu2, sigma2))\n\u001b[32m     59\u001b[39m actual_D3 = compute_distance_torch(embeddings, selected, nonZ)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m mu3, sigma3 = compute_distribution(\u001b[38;5;28;01mlambda\u001b[39;00m s: \u001b[43mcompute_distance_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonZ\u001b[49m\u001b[43m)\u001b[49m, Z_indices)\n\u001b[32m     61\u001b[39m results[\u001b[33m\"\u001b[39m\u001b[33mD3 (to Y-Z)\u001b[39m\u001b[33m\"\u001b[39m] = (actual_D3, mu3, sigma3, get_z(actual_D3, mu3, sigma3))\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mcompute_distance_torch\u001b[39m\u001b[34m(embeddings, A, B)\u001b[39m\n\u001b[32m     17\u001b[39m B_emb = embeddings[B]\n\u001b[32m     18\u001b[39m sim = torch.nn.functional.cosine_similarity(\n\u001b[32m     19\u001b[39m     A_emb.unsqueeze(\u001b[32m1\u001b[39m), B_emb.unsqueeze(\u001b[32m0\u001b[39m), dim=\u001b[32m2\u001b[39m\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43msim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def concat_instruction_response(example):\n",
    "    return {\n",
    "        \"output\": example[\"instruction\"] + \"\\n\\n\" + example[\"response\"]\n",
    "    }\n",
    "\n",
    "# Ensure 'split' column exists with default \"train\"\n",
    "if 'split' not in df.columns:\n",
    "    df['split'] = \"train\"\n",
    "\n",
    "for i in tqdm(range(len(all_results))):\n",
    "    \n",
    "    tempdf1 = df[df['id'] == all_ids[i]].reset_index(drop=True)\n",
    "    tempdf2 = df[\n",
    "        (df['id'] == all_results[i]['closest_indicators_ids'][0]) |\n",
    "        (df['id'] == all_results[i]['closest_indicators_ids'][1])\n",
    "    ].reset_index(drop=True)\n",
    "    tempdf = pd.concat([tempdf1, tempdf2]).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    for t in tqdm(all_results[i]['selected_topics'], leave=False):\n",
    "        \n",
    "        tempdf_t = tempdf1[tempdf1['context_template'] == t].reset_index(drop=True)\n",
    "        main_irs = tempdf_t.apply(concat_instruction_response, axis=1).apply(lambda x: x['output']).tolist()\n",
    "        all_irs = tempdf.apply(concat_instruction_response, axis=1).apply(lambda x: x['output']).tolist()\n",
    "        \n",
    "\n",
    "        Z_indices = [all_irs.index(m) for m in main_irs]\n",
    "        selected_ids, results, embeddings = find_diverse_subset_from_Z(all_irs, Z_indices, x=50)\n",
    "        selected_rows = tempdf_t.iloc[selected_ids]\n",
    "\n",
    "        # update split\n",
    "        for idx in selected_rows.index:\n",
    "            row = tempdf_t.loc[idx]\n",
    "            df.loc[\n",
    "                (df['id'] == all_ids[i]) &\n",
    "                (df['context_template'] == t) &\n",
    "                (df['instruction'] == row['instruction']),\n",
    "                'split'\n",
    "            ] = 'test'\n",
    "\n",
    "        remaining_rows = tempdf_t.drop(selected_rows.index)\n",
    "        for idx in remaining_rows.index:\n",
    "            row = tempdf_t.loc[idx]\n",
    "            df.loc[\n",
    "                (df['id'] == all_ids[i]) &\n",
    "                (df['context_template'] == t) &\n",
    "                (df['instruction'] == row['instruction']),\n",
    "                'split'\n",
    "            ] = 'val'\n",
    "\n",
    "        t4 = time.perf_counter()\n",
    "        print(f\"Topic loop timing: filtering={t3-t2:.2f}s, updating split={t4-t3:.2f}s\")\n",
    "\n",
    "    print(f\"Iteration {i}: prep={t1-t0:.2f}s, per-topic={t4-t2:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1773172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#load a pickle file\n",
    "with open(f\"/datadrive/pavan/CurLL/nanotron/inference_results_test.pkl\", \"rb\") as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7699f064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_prompt_text': \"<|user|>I'm going to say three letters, and you tell me which one doesn't belong, and why. Okay? Here they are: A, P, and 2. Which one is different?<|assistant|>\",\n",
       " 'generated_response': \"<|user|>\\n<|user|> word First<|user|><|user|><|user|><|user|>'s<|user|>,<|user|>.'m<|user|><|user|><|user|><|user|>,<|user|> you<|user|> First going<|user|><|user|><|user|><|user|>,<|user|>...<|user|>'m to<|user|>\\n<|user|><|user|> I<|user|>.<|user|> going tell<|user|>,<|user|>\\n just\\n I<|user|> to three<|user|> let<|user|>'m going already'm<|user|> start sounds<|user|> really\\n<|user|> to<|user|> going<|user|> something,\\n thinking, to write<|user|> to<|user|> things but, to Leo tell two write say<|user|>, you Leo tell started you things some a<|user|> and tell have a thinking people., numbers<|user|> each me<|user|> foods to. starting were,\\n with if to, say like I\\n Can<|user|> them one say and we you'm a me<|user|> makes sounds your... o read you can if<|user|>'t't kids get, to! me part tell make really. me and to say how doesn the reach to because! then write me letter't letters. like I one try me a you quite that making if can is me, one't as which otherswhy me't which one is really and you.*. what quite one is't - why need Can Ready it fit would't quite andwhy me you they ofsound't quite! try* your tell go't* quite come Is. it you me... go\",\n",
       " 'dataset_entry': {'output': {'instruction': \"I'm going to say three letters, and you tell me which one doesn't belong, and why. Okay? Here they are: A, P, and 2. Which one is different?\",\n",
       "   'response': \"Two is different! Because A and P are letters, and you can read them. Two is a number, and you count with it. A says 'ah' like in apple!\"},\n",
       "  'id': 'i182',\n",
       "  'indicator': 'Know the name of each letter in the English alphabet and the most common sound (phoneme) associated with it. ',\n",
       "  'skill': 'English',\n",
       "  'subskill': 'Reading',\n",
       "  'goal': 'Word structure (phonics) (Stages 1 to 4 only) Learners develop the decoding skills that form the foundation of reading for all stages.',\n",
       "  'age_group': '5-11',\n",
       "  'stage': 1,\n",
       "  'context_template': 'Identify the odd one',\n",
       "  'word_list': 'playhouse',\n",
       "  'instruction': \"I'm going to say three letters, and you tell me which one doesn't belong, and why. Okay? Here they are: A, P, and 2. Which one is different?\",\n",
       "  'response': \"Two is different! Because A and P are letters, and you can read them. Two is a number, and you count with it. A says 'ah' like in apple!\",\n",
       "  'POS': 'Noun'},\n",
       " 'generated_logits': tensor([[ 1.1562,  1.5547,  0.3711,  ...,  3.7344,  1.9375, 19.8750],\n",
       "         [ 2.1094,  4.3750, -1.1875,  ...,  4.8750,  3.3594,  0.2090],\n",
       "         [ 1.7500,  1.6406,  0.3867,  ...,  3.9688,  1.8359, 20.0000],\n",
       "         ...,\n",
       "         [ 8.0625,  2.8594, -2.6719,  ...,  2.9375,  0.9883,  0.0591],\n",
       "         [15.8750,  2.8438, -2.2656,  ...,  1.9844, -0.6289, -0.7383],\n",
       "         [10.6250,  2.2656, -3.1562,  ...,  2.2188, -0.3828, -0.3516]]),\n",
       " 'lm_loss': 1.3472890853881836,\n",
       " 'perplexity': 3.846982479095459}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c54b30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
