{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efe84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8035e",
   "metadata": {},
   "source": [
    "## Seed Words: Age of Acquistion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ab0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a huggingface dataset\n",
    "aoa = load_dataset(\"StephanAkkerman/English-Age-of-Acquisition\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a2d52c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>abacuses</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Alternative.spelling   Freq_pm Dom_PoS_SUBTLEX  Nletters  Nphon  \\\n",
       "0         a                    a  20415.27         Article         1      1   \n",
       "1  aardvark             aardvark      0.41            Noun         8      7   \n",
       "2    abacus               abacus      0.24            Noun         6      6   \n",
       "3  abacuses             abacuses      0.02            Noun         8      9   \n",
       "4   abalone              abalone      0.51            Verb         7      7   \n",
       "\n",
       "   Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  Perc_known_lem  \\\n",
       "0      1                 a     2.89        1.00         2.89            1.00   \n",
       "1      2          aardvark     9.89        1.00         9.89            1.00   \n",
       "2      3            abacus     8.69        0.65         8.69            0.65   \n",
       "3      4            abacus      NaN         NaN         8.69            0.65   \n",
       "4      4           abalone    12.23        0.72        12.23            0.72   \n",
       "\n",
       "   AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "0          3.16              NaN           NaN         NaN  \n",
       "1           NaN              NaN           NaN         NaN  \n",
       "2           NaN              NaN           NaN         NaN  \n",
       "3           NaN              NaN           NaN         NaN  \n",
       "4           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa = pd.DataFrame(aoa)\n",
    "aoa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de8d8762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Article</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noun</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noun</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noun</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Verb</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dom_PoS_SUBTLEX Lemma_highest_PoS  AoA_Kup_lem  Perc_known_lem\n",
       "0         Article                 a         2.89            1.00\n",
       "1            Noun          aardvark         9.89            1.00\n",
       "2            Noun            abacus         8.69            0.65\n",
       "3            Noun            abacus         8.69            0.65\n",
       "4            Verb           abalone        12.23            0.72"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa = aoa[[\"Dom_PoS_SUBTLEX\", \"Lemma_highest_PoS\", \"AoA_Kup_lem\", \"Perc_known_lem\"]]\n",
    "aoa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf77aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "aoa = aoa.drop_duplicates(subset=[\"Lemma_highest_PoS\", \"AoA_Kup_lem\"])\n",
    "aoa = aoa.dropna()\n",
    "aoa = aoa.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbd8732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25652"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa[aoa['AoA_Kup_lem']<=14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "329ec93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_0 = aoa[aoa['AoA_Kup_lem']<=5].reset_index(drop=True)\n",
    "stage_1 = aoa[(aoa['AoA_Kup_lem']>5) & (aoa['AoA_Kup_lem']<=6)].reset_index(drop=True)\n",
    "stage_2 = aoa[(aoa['AoA_Kup_lem']>6) & (aoa['AoA_Kup_lem']<=7)].reset_index(drop=True)\n",
    "stage_3 = aoa[(aoa['AoA_Kup_lem']>7) & (aoa['AoA_Kup_lem']<=8)].reset_index(drop=True)\n",
    "stage_4 = aoa[(aoa['AoA_Kup_lem']>8) & (aoa['AoA_Kup_lem']<=9)].reset_index(drop=True)\n",
    "stage_5 = aoa[(aoa['AoA_Kup_lem']>9) & (aoa['AoA_Kup_lem']<=10)].reset_index(drop=True)\n",
    "stage_6 = aoa[(aoa['AoA_Kup_lem']>10) & (aoa['AoA_Kup_lem']<=11)].reset_index(drop=True)\n",
    "stage_7 = aoa[(aoa['AoA_Kup_lem']>11) & (aoa['AoA_Kup_lem']<=12)].reset_index(drop=True)\n",
    "stage_8 = aoa[(aoa['AoA_Kup_lem']>12) & (aoa['AoA_Kup_lem']<=13)].reset_index(drop=True)\n",
    "stage_9 = aoa[(aoa['AoA_Kup_lem']>13) & (aoa['AoA_Kup_lem']<=14)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b69c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stage_words(stage_df):\n",
    "    filtered_df = stage_df[stage_df['Dom_PoS_SUBTLEX'].isin(['Noun', 'Verb', 'Adjective', 'Adverb'])]\n",
    "    filtered_df = filtered_df.sort_values(by=[\"Perc_known_lem\"], ascending=False)\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    stage_words = list(zip(filtered_df['Lemma_highest_PoS'], filtered_df['Dom_PoS_SUBTLEX']))\n",
    "    return stage_words, filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1031927",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_0, df_0 = get_stage_words(stage_0)\n",
    "words_1, df_1 = get_stage_words(stage_1)\n",
    "words_2, df_2 = get_stage_words(stage_2)\n",
    "words_3, df_3 = get_stage_words(stage_3)\n",
    "words_4, df_4 = get_stage_words(stage_4)\n",
    "words_5, df_5 = get_stage_words(stage_5)\n",
    "words_6, df_6 = get_stage_words(stage_6)\n",
    "words_7, df_7 = get_stage_words(stage_7)\n",
    "words_8, df_8 = get_stage_words(stage_8)\n",
    "words_9, df_9 = get_stage_words(stage_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1120d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:  903\n",
      "Stage 1:  964\n",
      "Stage 2:  1386\n",
      "Stage 3:  1859\n",
      "Stage 4:  2579\n",
      "Stage 5:  3147\n",
      "Stage 6:  3605\n",
      "Stage 7:  3821\n",
      "Stage 8:  3768\n",
      "Stage 9:  3143\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 0: \", len(words_0))\n",
    "print(\"Stage 1: \", len(words_1))\n",
    "print(\"Stage 2: \", len(words_2))\n",
    "print(\"Stage 3: \", len(words_3))\n",
    "print(\"Stage 4: \", len(words_4))\n",
    "print(\"Stage 5: \", len(words_5))\n",
    "print(\"Stage 6: \", len(words_6))\n",
    "print(\"Stage 7: \", len(words_7))\n",
    "print(\"Stage 8: \", len(words_8))\n",
    "print(\"Stage 9: \", len(words_9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "441be523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_seeds_and_leftovers(save_dir, num_seeds):\n",
    "    for i in range(num_seeds):\n",
    "        words = globals().get(f\"words_{i}\")\n",
    "        with open(f\"{save_dir}{i}/seed/seed_words.pkl\", \"wb\") as f:\n",
    "            pickle.dump(words, f)\n",
    "        df_var = globals().get(f\"df_{i}\")\n",
    "        df_var.to_csv(f\"{save_dir}{i}/seed/df_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f54932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directories if they do not exist\n",
    "for i in range(10):\n",
    "    os.makedirs(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/instruct/\", exist_ok=True)\n",
    "    os.makedirs(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/context/\", exist_ok=True)\n",
    "    os.makedirs(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/raw/instruct/\", exist_ok=True)\n",
    "    os.makedirs(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/raw/context/\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9741557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/datadrive/pavan/az_storage/data_unorganized/stages/stage\"\n",
    "save_seeds_and_leftovers(save_dir, num_seeds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78fcad",
   "metadata": {},
   "source": [
    "### Recheck the saved seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8faf6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:  903\n",
      "Stage 1:  964\n",
      "Stage 2:  1386\n",
      "Stage 3:  1859\n",
      "Stage 4:  2579\n",
      "Stage 5:  3147\n",
      "Stage 6:  3605\n",
      "Stage 7:  3821\n",
      "Stage 8:  3768\n",
      "Stage 9:  3143\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    #load the words\n",
    "    with open(f\"{save_dir}{i}/seed/seed_words.pkl\", \"rb\") as f:\n",
    "        words = pickle.load(f)\n",
    "\n",
    "    print(f\"Stage {i}: \", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc463254",
   "metadata": {},
   "source": [
    "## Stage-wise Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1915453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/skill_graph/version2/graph_final.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d80c9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = {}\n",
    "for i in range(10):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/seed_words.pkl\", \"rb\") as f:\n",
    "        seed_words[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43166167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d9ab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:  903\n",
      "Stage 1:  964\n",
      "Stage 2:  1386\n",
      "Stage 3:  1859\n",
      "Stage 4:  2579\n",
      "Stage 5:  3147\n",
      "Stage 6:  3605\n",
      "Stage 7:  3821\n",
      "Stage 8:  3768\n",
      "Stage 9:  3143\n"
     ]
    }
   ],
   "source": [
    "for k in seed_words:\n",
    "    print(f\"Stage {k}: \", len(seed_words[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dae0d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of context templates:  52770\n",
      "Total number of instruction templates:  53284\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "ir = 0\n",
    "for node in DG.nodes():\n",
    "    c+= len(DG.nodes[node]['context_templates'])\n",
    "    ir+= len(DG.nodes[node]['ins_templates'])\n",
    "print(\"Total number of context templates: \", c)\n",
    "print(\"Total number of instruction templates: \", ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78af542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2776 [00:00<01:58, 23.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2776/2776 [05:44<00:00,  8.07it/s]\n"
     ]
    }
   ],
   "source": [
    "seed_data = {}\n",
    "for i in range(10):\n",
    "    seed_data[i] = {\"context\": [], \"instruct\": []}\n",
    "\n",
    "for node in tqdm(DG.nodes()):\n",
    "    stage = DG.nodes[node]['stage']\n",
    "    for context in DG.nodes[node]['context_templates']:\n",
    "        for word in seed_words[stage]:\n",
    "            seed_data[stage]['context'].append({\n",
    "                    \"id\": node,\n",
    "                    \"indicator\": DG.nodes[node]['label'],\n",
    "                    \"skill\": DG.nodes[node]['skill'],\n",
    "                    \"subskill\": DG.nodes[node]['subskill'],\n",
    "                    \"goal\": DG.nodes[node]['goal'],\n",
    "                    \"age_group\": DG.nodes[node]['age_group'],\n",
    "                    \"stage\": DG.nodes[node]['stage'],\n",
    "                    \"context_template\": context,\n",
    "                    \"word_list\": word\n",
    "                })\n",
    "\n",
    "    for instruct in DG.nodes[node]['ins_templates']:\n",
    "        for word in seed_words[stage]:\n",
    "            seed_data[stage]['instruct'].append({\n",
    "                    \"id\": node,\n",
    "                    \"indicator\": DG.nodes[node]['label'],\n",
    "                    \"skill\": DG.nodes[node]['skill'],\n",
    "                    \"subskill\": DG.nodes[node]['subskill'],\n",
    "                    \"goal\": DG.nodes[node]['goal'],\n",
    "                    \"age_group\": DG.nodes[node]['age_group'],\n",
    "                    \"stage\": DG.nodes[node]['stage'],\n",
    "                    \"context_template\": instruct,\n",
    "                    \"word_list\": word\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4f90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:  3006990 3320331\n",
      "Stage 1:  4038196 4120136\n",
      "Stage 2:  6514200 6668046\n",
      "Stage 3:  11598301 11763752\n",
      "Stage 4:  14158710 14310871\n",
      "Stage 5:  15231480 15187422\n",
      "Stage 6:  24658200 24625755\n",
      "Stage 7:  19162315 18978907\n",
      "Stage 8:  20305752 20090976\n",
      "Stage 9:  21177534 21023527\n"
     ]
    }
   ],
   "source": [
    "for k in seed_data:\n",
    "    print(f\"Stage {k}: \", len(seed_data[k]['context']), len(seed_data[k]['instruct']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dd5ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:\n",
      "  Language and Communication: 394611 instances, 24 unique instances\n",
      "  Literacy: 316050 instances, 20 unique instances\n",
      "  Mathematics Development: 413574 instances, 26 unique instances\n",
      "  Scientific Reasoning: 305214 instances, 18 unique instances\n",
      "  Perceptual, Motor, and Physical Development: 297990 instances, 17 unique instances\n",
      "  Approaches to Learning: 670026 instances, 41 unique instances\n",
      "  Social and Emotional Development: 609525 instances, 36 unique instances\n",
      "***************\n",
      "Stage 1:\n",
      "  English: 1648440 instances, 90 unique instances\n",
      "  Mathematics: 650700 instances, 37 unique instances\n",
      "  Science: 667088 instances, 37 unique instances\n",
      "  Computing: 521524 instances, 28 unique instances\n",
      "  Global Perspectives: 327760 instances, 18 unique instances\n",
      "  Digital Literacy: 222684 instances, 11 unique instances\n",
      "***************\n",
      "Stage 2:\n",
      "  English: 2562714 instances, 99 unique instances\n",
      "  Mathematics: 1222452 instances, 48 unique instances\n",
      "  Science: 1086624 instances, 42 unique instances\n",
      "  Computing: 819126 instances, 31 unique instances\n",
      "  Global Perspectives: 493416 instances, 18 unique instances\n",
      "  Digital Literacy: 329868 instances, 13 unique instances\n",
      "***************\n",
      "Stage 3:\n",
      "  English: 3582293 instances, 102 unique instances\n",
      "  Mathematics: 1847846 instances, 53 unique instances\n",
      "  Science: 1719575 instances, 49 unique instances\n",
      "  Computing: 1334762 instances, 36 unique instances\n",
      "  Humanities: 2636062 instances, 75 unique instances\n",
      "  Digital Literacy: 477763 instances, 14 unique instances\n",
      "***************\n",
      "Stage 4:\n",
      "  English: 5274055 instances, 106 unique instances\n",
      "  Mathematics: 2266941 instances, 47 unique instances\n",
      "  Science: 3009693 instances, 61 unique instances\n",
      "  Computing: 1936829 instances, 39 unique instances\n",
      "  Global Perspectives: 879439 instances, 18 unique instances\n",
      "  Digital Literacy: 791753 instances, 16 unique instances\n",
      "***************\n",
      "Stage 5:\n",
      "  English: 5567043 instances, 93 unique instances\n",
      "  Mathematics: 3027414 instances, 52 unique instances\n",
      "  Science: 3304350 instances, 56 unique instances\n",
      "  Computing: 2423190 instances, 40 unique instances\n",
      "  Digital Literacy: 909483 instances, 15 unique instances\n",
      "***************\n",
      "Stage 6:\n",
      "  English: 6467370 instances, 94 unique instances\n",
      "  Mathematics: 3680705 instances, 55 unique instances\n",
      "  Science: 3803275 instances, 57 unique instances\n",
      "  Computing: 2710960 instances, 40 unique instances\n",
      "  Humanities: 5659850 instances, 82 unique instances\n",
      "  Global Perspectives: 1225700 instances, 18 unique instances\n",
      "  Digital Literacy: 1110340 instances, 16 unique instances\n",
      "***************\n",
      "Stage 7:\n",
      "  Mathematics: 4631052 instances, 63 unique instances\n",
      "  Science: 5303548 instances, 72 unique instances\n",
      "  Computing: 3022411 instances, 42 unique instances\n",
      "  Digital Literacy: 1031670 instances, 14 unique instances\n",
      "  English: 5173634 instances, 70 unique instances\n",
      "***************\n",
      "Stage 8:\n",
      "  Mathematics: 4310592 instances, 61 unique instances\n",
      "  Science: 5120712 instances, 70 unique instances\n",
      "  Computing: 3176424 instances, 43 unique instances\n",
      "  Digital Literacy: 1096488 instances, 15 unique instances\n",
      "  Global Perspectives: 1341408 instances, 18 unique instances\n",
      "  English: 5260128 instances, 71 unique instances\n",
      "***************\n",
      "Stage 9:\n",
      "  Mathematics: 3300150 instances, 55 unique instances\n",
      "  Science: 4236764 instances, 70 unique instances\n",
      "  Computing: 2658978 instances, 45 unique instances\n",
      "  Digital Literacy: 914613 instances, 15 unique instances\n",
      "  Global Perspectives: 1112622 instances, 18 unique instances\n",
      "  Humanities: 4840220 instances, 79 unique instances\n",
      "  English: 4114187 instances, 67 unique instances\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "skill_dict = {}\n",
    "for i in tqdm(seed_data):\n",
    "    if i not in skill_dict:\n",
    "        skill_dict[i] = {}\n",
    "    for j in seed_data[i]['context']:\n",
    "        if j['skill'] not in skill_dict[i]:\n",
    "            skill_dict[i][j['skill']] = []\n",
    "        skill_dict[i][j['skill']].append(j['id'])\n",
    "\n",
    "for stage in skill_dict:\n",
    "    print(f\"Stage {stage}:\")\n",
    "    for skill in skill_dict[stage]:\n",
    "        print(f\"  {skill}: {len(skill_dict[stage][skill])} instances, {len(set(skill_dict[stage][skill]))} unique instances\")\n",
    "        skill_dict[stage][skill] = list(set(skill_dict[stage][skill]))\n",
    "    print(\"***************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d89e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:\n",
      "  Language and Communication: 443373 instances, 24 unique instances\n",
      "  Literacy: 423507 instances, 20 unique instances\n",
      "  Mathematics Development: 459627 instances, 26 unique instances\n",
      "  Scientific Reasoning: 317856 instances, 18 unique instances\n",
      "  Perceptual, Motor, and Physical Development: 282639 instances, 17 unique instances\n",
      "  Approaches to Learning: 742266 instances, 41 unique instances\n",
      "  Social and Emotional Development: 651063 instances, 36 unique instances\n",
      "***************\n",
      "Stage 1:\n",
      "  English: 1712064 instances, 90 unique instances\n",
      "  Mathematics: 700828 instances, 37 unique instances\n",
      "  Science: 681548 instances, 37 unique instances\n",
      "  Computing: 508028 instances, 28 unique instances\n",
      "  Global Perspectives: 315228 instances, 18 unique instances\n",
      "  Digital Literacy: 202440 instances, 11 unique instances\n",
      "***************\n",
      "Stage 2:\n",
      "  English: 2623698 instances, 99 unique instances\n",
      "  Mathematics: 1226610 instances, 48 unique instances\n",
      "  Science: 1124046 instances, 42 unique instances\n",
      "  Computing: 878724 instances, 31 unique instances\n",
      "  Global Perspectives: 480942 instances, 18 unique instances\n",
      "  Digital Literacy: 334026 instances, 13 unique instances\n",
      "***************\n",
      "Stage 3:\n",
      "  English: 3714282 instances, 102 unique instances\n",
      "  Mathematics: 1816243 instances, 53 unique instances\n",
      "  Science: 1704703 instances, 49 unique instances\n",
      "  Computing: 1349634 instances, 36 unique instances\n",
      "  Humanities: 2699268 instances, 75 unique instances\n",
      "  Digital Literacy: 479622 instances, 14 unique instances\n",
      "***************\n",
      "Stage 4:\n",
      "  English: 5173474 instances, 106 unique instances\n",
      "  Mathematics: 2230835 instances, 47 unique instances\n",
      "  Science: 3069010 instances, 61 unique instances\n",
      "  Computing: 2230835 instances, 39 unique instances\n",
      "  Global Perspectives: 856228 instances, 18 unique instances\n",
      "  Digital Literacy: 750489 instances, 16 unique instances\n",
      "***************\n",
      "Stage 5:\n",
      "  English: 5538720 instances, 93 unique instances\n",
      "  Mathematics: 2995944 instances, 52 unique instances\n",
      "  Science: 3332673 instances, 56 unique instances\n",
      "  Computing: 2426337 instances, 40 unique instances\n",
      "  Digital Literacy: 893748 instances, 15 unique instances\n",
      "***************\n",
      "Stage 6:\n",
      "  English: 6362825 instances, 94 unique instances\n",
      "  Mathematics: 3691520 instances, 55 unique instances\n",
      "  Science: 3929450 instances, 57 unique instances\n",
      "  Computing: 2757825 instances, 40 unique instances\n",
      "  Humanities: 5576935 instances, 82 unique instances\n",
      "  Global Perspectives: 1204070 instances, 18 unique instances\n",
      "  Digital Literacy: 1103130 instances, 16 unique instances\n",
      "***************\n",
      "Stage 7:\n",
      "  Mathematics: 4497317 instances, 63 unique instances\n",
      "  Science: 5276801 instances, 72 unique instances\n",
      "  Computing: 3091189 instances, 42 unique instances\n",
      "  Digital Literacy: 997281 instances, 14 unique instances\n",
      "  English: 5116319 instances, 70 unique instances\n",
      "***************\n",
      "Stage 8:\n",
      "  Mathematics: 4325664 instances, 61 unique instances\n",
      "  Science: 5143320 instances, 70 unique instances\n",
      "  Computing: 3074688 instances, 43 unique instances\n",
      "  Digital Literacy: 1100256 instances, 15 unique instances\n",
      "  Global Perspectives: 1292424 instances, 18 unique instances\n",
      "  English: 5154624 instances, 71 unique instances\n",
      "***************\n",
      "Stage 9:\n",
      "  Mathematics: 3215289 instances, 55 unique instances\n",
      "  Science: 4224192 instances, 70 unique instances\n",
      "  Computing: 2662121 instances, 45 unique instances\n",
      "  Digital Literacy: 939757 instances, 15 unique instances\n",
      "  Global Perspectives: 1084335 instances, 18 unique instances\n",
      "  Humanities: 4909366 instances, 79 unique instances\n",
      "  English: 3988467 instances, 67 unique instances\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "skill_dict = {}\n",
    "for i in tqdm(seed_data):\n",
    "    if i not in skill_dict:\n",
    "        skill_dict[i] = {}\n",
    "    for j in seed_data[i]['instruct']:\n",
    "        if j['skill'] not in skill_dict[i]:\n",
    "            skill_dict[i][j['skill']] = []\n",
    "        skill_dict[i][j['skill']].append(j['id'])\n",
    "\n",
    "for stage in skill_dict:\n",
    "    print(f\"Stage {stage}:\")\n",
    "    for skill in skill_dict[stage]:\n",
    "        print(f\"  {skill}: {len(skill_dict[stage][skill])} instances, {len(set(skill_dict[stage][skill]))} unique instances\")\n",
    "        skill_dict[stage][skill] = list(set(skill_dict[stage][skill]))\n",
    "    print(\"***************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a117872",
   "metadata": {},
   "source": [
    "### Random 1000 for prompt checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "479f4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save random 1000 samples for each stage\n",
    "seed_data_sample = {}\n",
    "for i in range(10):\n",
    "    seed_data_sample[i] = {\"context\": [], \"instruct\": []}\n",
    "for i in range(10):\n",
    "    seed_data_sample[i]['context'] = random.sample(seed_data[i]['context'], 1000)\n",
    "    seed_data_sample[i]['instruct'] = random.sample(seed_data[i]['instruct'], 1000)\n",
    "for i in range(10):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/instruct/random_1000.jsonl\", \"w\") as f:\n",
    "        json.dump(seed_data_sample[i]['instruct'], f, indent=4)\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/context/random_1000.jsonl\", \"w\") as f:\n",
    "        json.dump(seed_data_sample[i]['context'], f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db1402",
   "metadata": {},
   "source": [
    "### Stage 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ee39ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 11\n",
    "stage = 0\n",
    "type = \"context\"\n",
    "chunk_size = len(seed_data[stage][type]) // num_gpus\n",
    "chunks = [seed_data[stage][type][i:i + chunk_size] for i in range(0, len(seed_data[stage][type]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/chunk_{i}.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/metadata_chunks.jsonl\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bcddd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3006990, 12, 273362)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_data[stage][type]), len(chunks), chunk_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40027dc",
   "metadata": {},
   "source": [
    "### Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d0d3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 9\n",
    "stage = 1\n",
    "type = \"context\"\n",
    "chunk_size = len(seed_data[stage][type]) // num_gpus\n",
    "chunks = [seed_data[stage][type][i:i + chunk_size] for i in range(0, len(seed_data[stage][type]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/chunk_{i}.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/metadata_chunks.jsonl\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0547179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4038196, 10, 448688)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_data[stage][type]), len(chunks), chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbe4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\n",
      "\n",
      "Your task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. **Context Generation:**\n",
      "   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\n",
      "   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\n",
      "   - Expand the selected word into a more detailed, skill-aligned topic.\n",
      "   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\n",
      "   - The generated text should be **between 250 and 500 words**.\n",
      "   - The text must clearly align with the skill, subskill, goal, and indicator.\n",
      "   - The selected word does not need to explicitly appear in the final text.\n",
      "\n",
      "2. **Writing Style:**\n",
      "   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\n",
      "   - Include actions, feelings, interactions, and details to make the text rich and lively.\n",
      "   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\n",
      "\n",
      "3. **Output Format:** Strictly return the output in the following JSON structure:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n",
      "Only output the JSON. No additional commentary.\n",
      "____________________________________\n",
      "Generate a rich and engaging context text based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate a detailed text of **250–500 words** following the context template.\n",
      "- Enrich the text with actions, emotions, and interactions.\n",
      "\n",
      "Output strictly in this format:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "simple_context_prompts = {\n",
    "    \"system\": \"You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\\n\\nYour task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. **Context Generation:**\\n   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\\n   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\\n   - Expand the selected word into a more detailed, skill-aligned topic.\\n   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\\n   - The generated text should be **between 250 and 500 words**.\\n   - The text must clearly align with the skill, subskill, goal, and indicator.\\n   - The selected word does not need to explicitly appear in the final text.\\n\\n2. **Writing Style:**\\n   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\\n   - Include actions, feelings, interactions, and details to make the text rich and lively.\\n   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\\n\\n3. **Output Format:** Strictly return the output in the following JSON structure:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\\nOnly output the JSON. No additional commentary.\",\n",
    "    \"user\": \"Generate a rich and engaging context text based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate a detailed text of **250–500 words** following the context template.\\n- Enrich the text with actions, emotions, and interactions.\\n\\nOutput strictly in this format:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(simple_context_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(simple_context_prompts['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9496f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt.json\", \"w\") as f:\n",
    "    json.dump(simple_context_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1273c7",
   "metadata": {},
   "source": [
    "### Stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 6\n",
    "stage = 2\n",
    "chunk_size = len(seed_data_c[stage]) // num_gpus\n",
    "chunks = [seed_data_c[stage][i:i + chunk_size] for i in range(0, len(seed_data_c[stage]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/context/c_{i}_seed.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/context/c_seed_metadata.json\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53bd8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 6\n",
    "stage = 2\n",
    "chunk_size = len(seed_data_ins[stage]) // num_gpus\n",
    "chunks = [seed_data_ins[stage][i:i + chunk_size] for i in range(0, len(seed_data_ins[stage]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/instruct/ins_{i}_seed.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/instruct/ins_seed_metadata.json\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cce14a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/context/prompt.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/context/chunk_1.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/chunk_1.jsonl -t 1.0\n",
    "#dnn4\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/context/prompt.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/context/chunk_2.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/chunk_2.jsonl -t 1.0\n",
    "#dnn4\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/context/prompt.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/context/chunk_3.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/chunk_3.jsonl -t 1.0\n",
    "#2A100s\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/184cd830ee604c1ab684a7be1a080212/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/prompt.json -s /scratch/azureml/cr/j/184cd830ee604c1ab684a7be1a080212/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/chunk_4.jsonl -o /scratch/azureml/cr/j/184cd830ee604c1ab684a7be1a080212/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/context/chunk_4.jsonl -t 1.0\n",
    "#8A100s\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/prompt.json -s /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/chunk_5.jsonl -o /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/context/chunk_5.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/prompt.json -s /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/chunk_6.jsonl -o /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/context/chunk_6.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=4,5 python general_generation.py -p /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/prompt.json -s /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/chunk_7.jsonl -o /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/context/chunk_7.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=6,7 python general_generation.py -p /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/prompt.json -s /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/chunk_8.jsonl -o /scratch/azureml/cr/j/a358b42e46974e1397bed72365207959/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/context/chunk_8.jsonl -t 1.0\n",
    "#4A100s\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/44dd3d903d6e472a923bca0af5051fd8/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/prompt.json -s /scratch/azureml/cr/j/44dd3d903d6e472a923bca0af5051fd8/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/chunk_9.jsonl -o /scratch/azureml/cr/j/44dd3d903d6e472a923bca0af5051fd8/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/context/chunk_9.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /scratch/azureml/cr/j/44dd3d903d6e472a923bca0af5051fd8/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/prompt.json -s /scratch/azureml/cr/j/44dd3d903d6e472a923bca0af5051fd8/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/context/chunk_10.jsonl -o /scratch/azureml/cr/j/44dd3d903d6e472a923bca0af5051fd8/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/context/chunk_10.jsonl -t 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490f6a5",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "755f299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\n",
      "\n",
      "Your task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. **Context Generation:**\n",
      "   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\n",
      "   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\n",
      "   - Expand the selected word into a more detailed, skill-aligned topic.\n",
      "   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\n",
      "   - The generated text should be **between 250 and 500 words**.\n",
      "   - The text must clearly align with the skill, subskill, goal, and indicator.\n",
      "   - The selected word does not need to explicitly appear in the final text.\n",
      "\n",
      "2. **Writing Style:**\n",
      "   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\n",
      "   - Include actions, feelings, interactions, and details to make the text rich and lively.\n",
      "   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\n",
      "\n",
      "3. **Output Format:** Strictly return the output in the following JSON structure:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n",
      "Only output the JSON. No additional commentary.\n",
      "____________________________________\n",
      "Generate a rich and engaging context text based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate a detailed text of **250–500 words** following the context template.\n",
      "- Enrich the text with actions, emotions, and interactions.\n",
      "\n",
      "Output strictly in this format:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "simple_context_prompts = {\n",
    "    \"system\": \"You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\\n\\nYour task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. **Context Generation:**\\n   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\\n   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\\n   - Expand the selected word into a more detailed, skill-aligned topic.\\n   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\\n   - The generated text should be **between 250 and 500 words**.\\n   - The text must clearly align with the skill, subskill, goal, and indicator.\\n   - The selected word does not need to explicitly appear in the final text.\\n\\n2. **Writing Style:**\\n   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\\n   - Include actions, feelings, interactions, and details to make the text rich and lively.\\n   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\\n\\n3. **Output Format:** Strictly return the output in the following JSON structure:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\\nOnly output the JSON. No additional commentary.\",\n",
    "    \"user\": \"Generate a rich and engaging context text based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate a detailed text of **250–500 words** following the context template.\\n- Enrich the text with actions, emotions, and interactions.\\n\\nOutput strictly in this format:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(simple_context_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(simple_context_prompts['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71763aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/context/prompt.json\", \"w\") as f:\n",
    "    json.dump(simple_context_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae084dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\n",
      "\n",
      "Your task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\n",
      "\n",
      "Guidelines:\n",
      "\n",
      "1. Skill Alignment:\n",
      "   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\n",
      "   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\n",
      "   - The response should not pretend to be a child; it should simply model the appropriate behavior.\n",
      "\n",
      "2. Using the Word, Part-of-speech tuple:\n",
      "   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\n",
      "   - Expand the word into a topic relevant to the skill and age group.\n",
      "   - Neither the instruction nor the response must explicitly use the word, but the context should logically connect to it.\n",
      "\n",
      "3. Language Style:\n",
      "   - Keep vocabulary simple and concrete, matching the given age group and stage.\n",
      "   - Instructions should feel natural and actionable for the developmental level, even if a model is responding.\n",
      "\n",
      "4. Output Format:\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the word into a skill-relevant topic.\n",
      "- Generate an instruction based on the topic, targeting the skill/indicator.\n",
      "- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction_response_prompts = {\n",
    "    \"system\": \"You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\\n\\nYour task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\\n\\nGuidelines:\\n\\n1. Skill Alignment:\\n   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\\n   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\\n   - The response should not pretend to be a child; it should simply model the appropriate behavior.\\n\\n2. Using the Word, Part-of-speech tuple:\\n   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\\n   - Expand the word into a topic relevant to the skill and age group.\\n   - Neither the instruction nor the response must explicitly use the word, but the context should logically connect to it.\\n\\n3. Language Style:\\n   - Keep vocabulary simple and concrete, matching the given age group and stage.\\n   - Instructions should feel natural and actionable for the developmental level, even if a model is responding.\\n\\n4. Output Format:\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the word into a skill-relevant topic.\\n- Generate an instruction based on the topic, targeting the skill/indicator.\\n- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(instruction_response_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(instruction_response_prompts['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c257d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/prompt.json\", \"w\") as f:\n",
    "    json.dump(instruction_response_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ebe9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbd4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'selected_word': 'rainstorm', 'selected_word_pos': 'Noun', 'expanded_topic': 'Discussing a loud and startling weather event', 'instruction': \"I'm telling you about the big storm we had last night. It was very loud, and there were bright flashes. What do you think about that?\", 'response': 'Oh wow! That sounds... surprising. I think I would want to be close to someone if I heard that.'}, 'id': 'i0', 'indicator': 'Uses verbal and non-verbal signals appropriately to acknowledge the comments or questions of others.', 'skill': 'Language and Communication', 'subskill': 'Attending and Understanding', 'goal': 'Child attends to communication and language from others.', 'age_group': '0-5', 'stage': 0, 'context_template': 'Describe feeling outcomes', 'word_list': [['scared', 'Adjective'], ['guy', 'Noun'], ['rainstorm', 'Noun'], ['cake', 'Noun'], ['jelly', 'Noun'], ['library', 'Noun'], ['lightning', 'Noun'], ['whisper', 'Verb'], ['walk', 'Verb'], ['cheer', 'Verb']]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"/datadrive/pavan/CurLL/data/raw/instruct/ins_0_seed.jsonl\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae2efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:  I'm telling you about the dog I saw at the park. He was very fluffy and brown! What color did I say the dog was?\n",
      "Response:  Brown!\n"
     ]
    }
   ],
   "source": [
    "i = 100\n",
    "print(\"Instruction: \", data[i]['output'][\"instruction\"])\n",
    "print(\"Response: \", data[i]['output'][\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44bc93a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\n",
      "\n",
      "Your task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. **Context Generation:**\n",
      "   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\n",
      "   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\n",
      "   - Expand the selected word into a more detailed, skill-aligned topic.\n",
      "   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\n",
      "   - The generated text should be **between 250 and 500 words**.\n",
      "   - The text must clearly align with the skill, subskill, goal, and indicator.\n",
      "   - The selected word does not need to explicitly appear in the final text.\n",
      "\n",
      "2. **Writing Style:**\n",
      "   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\n",
      "   - Include actions, feelings, interactions, and details to make the text rich and lively.\n",
      "   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\n",
      "\n",
      "3. **Output Format:** Strictly return the output in the following JSON structure:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n",
      "Only output the JSON. No additional commentary.\n",
      "____________________________________\n",
      "Generate a rich and engaging context text based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate a detailed text of **250–500 words** following the context template.\n",
      "- Enrich the text with actions, emotions, and interactions.\n",
      "\n",
      "Output strictly in this format:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "simple_context_prompts = {\n",
    "    \"system\": \"You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\\n\\nYour task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. **Context Generation:**\\n   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\\n   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\\n   - Expand the selected word into a more detailed, skill-aligned topic.\\n   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\\n   - The generated text should be **between 250 and 500 words**.\\n   - The text must clearly align with the skill, subskill, goal, and indicator.\\n   - The selected word does not need to explicitly appear in the final text.\\n\\n2. **Writing Style:**\\n   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\\n   - Include actions, feelings, interactions, and details to make the text rich and lively.\\n   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\\n\\n3. **Output Format:** Strictly return the output in the following JSON structure:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\\nOnly output the JSON. No additional commentary.\",\n",
    "    \"user\": \"Generate a rich and engaging context text based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate a detailed text of **250–500 words** following the context template.\\n- Enrich the text with actions, emotions, and interactions.\\n\\nOutput strictly in this format:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(simple_context_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(simple_context_prompts['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93eacb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\n",
      "\n",
      "Your task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. Skill Alignment:\n",
      "   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\n",
      "   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\n",
      "   - The response should mimic the complexity of the language used by a child of that age group and stage.\n",
      "\n",
      "2. Using the Word, Part-of-speech tuple:\n",
      "   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\n",
      "   - Expand the word into a topic relevant to the skill and age group.\n",
      "   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\n",
      "   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\n",
      "\n",
      "3. Language Style:\n",
      "   - Keep vocabulary simple and concrete, matching the given age group and stage.\n",
      "\n",
      "4. Output Format:\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate an instruction based on the topic, targeting the skill/indicator.\n",
      "- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction_response_prompts = {\n",
    "    \"system\": \"You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\\n\\nYour task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. Skill Alignment:\\n   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\\n   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\\n   - The response should mimic the complexity of the language used by a child of that age group and stage.\\n\\n2. Using the Word, Part-of-speech tuple:\\n   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\\n   - Expand the word into a topic relevant to the skill and age group.\\n   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\\n   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\\n\\n3. Language Style:\\n   - Keep vocabulary simple and concrete, matching the given age group and stage.\\n\\n4. Output Format:\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate an instruction based on the topic, targeting the skill/indicator.\\n- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(instruction_response_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(instruction_response_prompts['user'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
