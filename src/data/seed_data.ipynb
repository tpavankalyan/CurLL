{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efe84d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datadrive/pavan/anaconda3/envs/gemma_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8035e",
   "metadata": {},
   "source": [
    "## Seed Words: Age of Acquistion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ab0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a huggingface dataset\n",
    "aoa = load_dataset(\"StephanAkkerman/English-Age-of-Acquisition\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a2d52c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Alternative.spelling</th>\n",
       "      <th>Freq_pm</th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Nletters</th>\n",
       "      <th>Nphon</th>\n",
       "      <th>Nsyll</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup</th>\n",
       "      <th>Perc_known</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "      <th>AoA_Bird_lem</th>\n",
       "      <th>AoA_Bristol_lem</th>\n",
       "      <th>AoA_Cort_lem</th>\n",
       "      <th>AoA_Schock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>Article</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Noun</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>abacuses</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Noun</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Verb</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Alternative.spelling   Freq_pm Dom_PoS_SUBTLEX  Nletters  Nphon  \\\n",
       "0         a                    a  20415.27         Article         1      1   \n",
       "1  aardvark             aardvark      0.41            Noun         8      7   \n",
       "2    abacus               abacus      0.24            Noun         6      6   \n",
       "3  abacuses             abacuses      0.02            Noun         8      9   \n",
       "4   abalone              abalone      0.51            Verb         7      7   \n",
       "\n",
       "   Nsyll Lemma_highest_PoS  AoA_Kup  Perc_known  AoA_Kup_lem  Perc_known_lem  \\\n",
       "0      1                 a     2.89        1.00         2.89            1.00   \n",
       "1      2          aardvark     9.89        1.00         9.89            1.00   \n",
       "2      3            abacus     8.69        0.65         8.69            0.65   \n",
       "3      4            abacus      NaN         NaN         8.69            0.65   \n",
       "4      4           abalone    12.23        0.72        12.23            0.72   \n",
       "\n",
       "   AoA_Bird_lem  AoA_Bristol_lem  AoA_Cort_lem  AoA_Schock  \n",
       "0          3.16              NaN           NaN         NaN  \n",
       "1           NaN              NaN           NaN         NaN  \n",
       "2           NaN              NaN           NaN         NaN  \n",
       "3           NaN              NaN           NaN         NaN  \n",
       "4           NaN              NaN           NaN         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa = pd.DataFrame(aoa)\n",
    "aoa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de8d8762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dom_PoS_SUBTLEX</th>\n",
       "      <th>Lemma_highest_PoS</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "      <th>Perc_known_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Article</td>\n",
       "      <td>a</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noun</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.89</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noun</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noun</td>\n",
       "      <td>abacus</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Verb</td>\n",
       "      <td>abalone</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dom_PoS_SUBTLEX Lemma_highest_PoS  AoA_Kup_lem  Perc_known_lem\n",
       "0         Article                 a         2.89            1.00\n",
       "1            Noun          aardvark         9.89            1.00\n",
       "2            Noun            abacus         8.69            0.65\n",
       "3            Noun            abacus         8.69            0.65\n",
       "4            Verb           abalone        12.23            0.72"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa = aoa[[\"Dom_PoS_SUBTLEX\", \"Lemma_highest_PoS\", \"AoA_Kup_lem\", \"Perc_known_lem\"]]\n",
    "aoa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf77aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "aoa = aoa.drop_duplicates(subset=[\"Lemma_highest_PoS\", \"AoA_Kup_lem\"])\n",
    "aoa = aoa.dropna()\n",
    "aoa = aoa.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbd8732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25652"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoa[aoa['AoA_Kup_lem']<=14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "329ec93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_0 = aoa[aoa['AoA_Kup_lem']<=5].reset_index(drop=True)\n",
    "stage_1 = aoa[(aoa['AoA_Kup_lem']>5) & (aoa['AoA_Kup_lem']<=6)].reset_index(drop=True)\n",
    "stage_2 = aoa[(aoa['AoA_Kup_lem']>6) & (aoa['AoA_Kup_lem']<=7)].reset_index(drop=True)\n",
    "stage_3 = aoa[(aoa['AoA_Kup_lem']>7) & (aoa['AoA_Kup_lem']<=8)].reset_index(drop=True)\n",
    "stage_4 = aoa[(aoa['AoA_Kup_lem']>8) & (aoa['AoA_Kup_lem']<=9)].reset_index(drop=True)\n",
    "stage_5 = aoa[(aoa['AoA_Kup_lem']>9) & (aoa['AoA_Kup_lem']<=10)].reset_index(drop=True)\n",
    "stage_6 = aoa[(aoa['AoA_Kup_lem']>10) & (aoa['AoA_Kup_lem']<=11)].reset_index(drop=True)\n",
    "stage_7 = aoa[(aoa['AoA_Kup_lem']>11) & (aoa['AoA_Kup_lem']<=12)].reset_index(drop=True)\n",
    "stage_8 = aoa[(aoa['AoA_Kup_lem']>12) & (aoa['AoA_Kup_lem']<=13)].reset_index(drop=True)\n",
    "stage_9 = aoa[(aoa['AoA_Kup_lem']>13) & (aoa['AoA_Kup_lem']<=14)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b69c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stage_words(stage_df):\n",
    "    filtered_df = stage_df[stage_df['Dom_PoS_SUBTLEX'].isin(['Noun', 'Verb', 'Adjective', 'Adverb'])]\n",
    "    filtered_df = filtered_df.sort_values(by=[\"Perc_known_lem\"], ascending=False)\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    stage_words = list(zip(filtered_df['Lemma_highest_PoS'], filtered_df['Dom_PoS_SUBTLEX']))\n",
    "    return stage_words, filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1031927",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_0, df_0 = get_stage_words(stage_0)\n",
    "words_1, df_1 = get_stage_words(stage_1)\n",
    "words_2, df_2 = get_stage_words(stage_2)\n",
    "words_3, df_3 = get_stage_words(stage_3)\n",
    "words_4, df_4 = get_stage_words(stage_4)\n",
    "words_5, df_5 = get_stage_words(stage_5)\n",
    "words_6, df_6 = get_stage_words(stage_6)\n",
    "words_7, df_7 = get_stage_words(stage_7)\n",
    "words_8, df_8 = get_stage_words(stage_8)\n",
    "words_9, df_9 = get_stage_words(stage_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1120d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:  903\n",
      "Stage 1:  964\n",
      "Stage 2:  1386\n",
      "Stage 3:  1859\n",
      "Stage 4:  2579\n",
      "Stage 5:  3147\n",
      "Stage 6:  3605\n",
      "Stage 7:  3821\n",
      "Stage 8:  3768\n",
      "Stage 9:  3143\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 0: \", len(words_0))\n",
    "print(\"Stage 1: \", len(words_1))\n",
    "print(\"Stage 2: \", len(words_2))\n",
    "print(\"Stage 3: \", len(words_3))\n",
    "print(\"Stage 4: \", len(words_4))\n",
    "print(\"Stage 5: \", len(words_5))\n",
    "print(\"Stage 6: \", len(words_6))\n",
    "print(\"Stage 7: \", len(words_7))\n",
    "print(\"Stage 8: \", len(words_8))\n",
    "print(\"Stage 9: \", len(words_9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "441be523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_seeds_and_leftovers(save_dir, num_seeds):\n",
    "    for i in range(num_seeds):\n",
    "        words = globals().get(f\"words_{i}\")\n",
    "        with open(f\"{save_dir}{i}/seed/seed_words.pkl\", \"wb\") as f:\n",
    "            pickle.dump(words, f)\n",
    "        df_var = globals().get(f\"df_{i}\")\n",
    "        df_var.to_csv(f\"{save_dir}{i}/seed/df_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f54932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directories if they do not exist\n",
    "for i in range(10):\n",
    "    os.makedirs(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/instruct/\", exist_ok=True)\n",
    "    os.makedirs(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/context/\", exist_ok=True)\n",
    "    os.makedirs(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/raw/instruct/\", exist_ok=True)\n",
    "    os.makedirs(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/raw/context/\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9741557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/datadrive/pavan/az_storage/data_unorganized/stages/stage\"\n",
    "save_seeds_and_leftovers(save_dir, num_seeds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78fcad",
   "metadata": {},
   "source": [
    "### Recheck the saved seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8faf6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:  903\n",
      "Stage 1:  964\n",
      "Stage 2:  1386\n",
      "Stage 3:  1859\n",
      "Stage 4:  2579\n",
      "Stage 5:  3147\n",
      "Stage 6:  3605\n",
      "Stage 7:  3821\n",
      "Stage 8:  3768\n",
      "Stage 9:  3143\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    #load the words\n",
    "    with open(f\"{save_dir}{i}/seed/seed_words.pkl\", \"rb\") as f:\n",
    "        words = pickle.load(f)\n",
    "\n",
    "    print(f\"Stage {i}: \", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc463254",
   "metadata": {},
   "source": [
    "## Stage-wise Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1915453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/skill_graph/version2/graph_final.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230c81ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Know the name of each letter in the English alphabet and the most common sound (phoneme) associated with it. ',\n",
       " 'age_group': '5-11',\n",
       " 'skill': 'English',\n",
       " 'subskill': 'Reading',\n",
       " 'goal': 'Word structure (phonics) (Stages 1 to 4 only) Learners develop the decoding skills that form the foundation of reading for all stages.',\n",
       " 'stage': 1,\n",
       " 'modality_textual': None,\n",
       " 'perspective': None,\n",
       " 'require_multimodal_context': None,\n",
       " 'embodied': None,\n",
       " 'ins_templates': ['Identify and name',\n",
       "  'Sound association practice',\n",
       "  'Categorize and sort',\n",
       "  'Pattern recognition task',\n",
       "  'Fill in the blank',\n",
       "  'Complete the sequence',\n",
       "  'Describe the relationship',\n",
       "  'What comes next?',\n",
       "  'Find the example',\n",
       "  'Define and illustrate',\n",
       "  'Explain the connection',\n",
       "  'Simple matching exercise',\n",
       "  'Identify the odd one',\n",
       "  'List and describe',\n",
       "  'How does it work?',\n",
       "  'Rewrite in different words',\n",
       "  'Give an example',\n",
       "  'Explain step-by-step'],\n",
       " 'context_templates': ['Descriptive scene setting',\n",
       "  'Simple comparative statements',\n",
       "  'Object property listing',\n",
       "  'Event sequence description',\n",
       "  'First-person observation report',\n",
       "  'Peer question exchange',\n",
       "  'Imaginary world description',\n",
       "  'Problem-solution narrative',\n",
       "  'Fictional diary entry',\n",
       "  'Character dialogue exchange',\n",
       "  'Short rhyming verse',\n",
       "  'Descriptive item catalog',\n",
       "  'Personal anecdote retelling',\n",
       "  'Simple prediction passage',\n",
       "  'Narrative event summary']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DG.nodes[\"i182\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80c9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = {}\n",
    "for i in range(10):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/seed_words.pkl\", \"rb\") as f:\n",
    "        seed_words[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43166167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d9ab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:  903\n",
      "Stage 1:  964\n",
      "Stage 2:  1386\n",
      "Stage 3:  1859\n",
      "Stage 4:  2579\n",
      "Stage 5:  3147\n",
      "Stage 6:  3605\n",
      "Stage 7:  3821\n",
      "Stage 8:  3768\n",
      "Stage 9:  3143\n"
     ]
    }
   ],
   "source": [
    "for k in seed_words:\n",
    "    print(f\"Stage {k}: \", len(seed_words[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dae0d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of context templates:  52770\n",
      "Total number of instruction templates:  53284\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "ir = 0\n",
    "for node in DG.nodes():\n",
    "    c+= len(DG.nodes[node]['context_templates'])\n",
    "    ir+= len(DG.nodes[node]['ins_templates'])\n",
    "print(\"Total number of context templates: \", c)\n",
    "print(\"Total number of instruction templates: \", ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2776 [00:00<02:15, 20.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2776/2776 [06:09<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "seed_data = {}\n",
    "for i in range(10):\n",
    "    seed_data[i] = {\"context\": [], \"instruct\": []}\n",
    "\n",
    "for node in tqdm(DG.nodes()):\n",
    "    stage = DG.nodes[node]['stage']\n",
    "    for context in DG.nodes[node]['context_templates']:\n",
    "        for word in seed_words[stage]:\n",
    "            seed_data[stage]['context'].append({\n",
    "                    \"id\": node,\n",
    "                    \"indicator\": DG.nodes[node]['label'],\n",
    "                    \"skill\": DG.nodes[node]['skill'],\n",
    "                    \"subskill\": DG.nodes[node]['subskill'],\n",
    "                    \"goal\": DG.nodes[node]['goal'],\n",
    "                    \"age_group\": DG.nodes[node]['age_group'],\n",
    "                    \"stage\": DG.nodes[node]['stage'],\n",
    "                    \"context_template\": context,\n",
    "                    \"word_list\": word\n",
    "                })\n",
    "\n",
    "    for instruct in DG.nodes[node]['ins_templates']:\n",
    "        for word in seed_words[stage]:\n",
    "            seed_data[stage]['instruct'].append({\n",
    "                    \"id\": node,\n",
    "                    \"indicator\": DG.nodes[node]['label'],\n",
    "                    \"skill\": DG.nodes[node]['skill'],\n",
    "                    \"subskill\": DG.nodes[node]['subskill'],\n",
    "                    \"goal\": DG.nodes[node]['goal'],\n",
    "                    \"age_group\": DG.nodes[node]['age_group'],\n",
    "                    \"stage\": DG.nodes[node]['stage'],\n",
    "                    \"context_template\": instruct,\n",
    "                    \"word_list\": word\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a4f90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:  3006990 3320331\n",
      "Stage 1:  4038196 4120136\n",
      "Stage 2:  6514200 6668046\n",
      "Stage 3:  11598301 11763752\n",
      "Stage 4:  14158710 14310871\n",
      "Stage 5:  15231480 15187422\n",
      "Stage 6:  24658200 24625755\n",
      "Stage 7:  19162315 18978907\n",
      "Stage 8:  20305752 20090976\n",
      "Stage 9:  21177534 21023527\n"
     ]
    }
   ],
   "source": [
    "for k in seed_data:\n",
    "    print(f\"Stage {k}: \", len(seed_data[k]['context']), len(seed_data[k]['instruct']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43dd5ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:\n",
      "  Language and Communication: 394611 instances, 24 unique instances\n",
      "  Literacy: 316050 instances, 20 unique instances\n",
      "  Mathematics Development: 413574 instances, 26 unique instances\n",
      "  Scientific Reasoning: 305214 instances, 18 unique instances\n",
      "  Perceptual, Motor, and Physical Development: 297990 instances, 17 unique instances\n",
      "  Approaches to Learning: 670026 instances, 41 unique instances\n",
      "  Social and Emotional Development: 609525 instances, 36 unique instances\n",
      "***************\n",
      "Stage 1:\n",
      "  English: 1648440 instances, 90 unique instances\n",
      "  Mathematics: 650700 instances, 37 unique instances\n",
      "  Science: 667088 instances, 37 unique instances\n",
      "  Computing: 521524 instances, 28 unique instances\n",
      "  Global Perspectives: 327760 instances, 18 unique instances\n",
      "  Digital Literacy: 222684 instances, 11 unique instances\n",
      "***************\n",
      "Stage 2:\n",
      "  English: 2562714 instances, 99 unique instances\n",
      "  Mathematics: 1222452 instances, 48 unique instances\n",
      "  Science: 1086624 instances, 42 unique instances\n",
      "  Computing: 819126 instances, 31 unique instances\n",
      "  Global Perspectives: 493416 instances, 18 unique instances\n",
      "  Digital Literacy: 329868 instances, 13 unique instances\n",
      "***************\n",
      "Stage 3:\n",
      "  English: 3582293 instances, 102 unique instances\n",
      "  Mathematics: 1847846 instances, 53 unique instances\n",
      "  Science: 1719575 instances, 49 unique instances\n",
      "  Computing: 1334762 instances, 36 unique instances\n",
      "  Humanities: 2636062 instances, 75 unique instances\n",
      "  Digital Literacy: 477763 instances, 14 unique instances\n",
      "***************\n",
      "Stage 4:\n",
      "  English: 5274055 instances, 106 unique instances\n",
      "  Mathematics: 2266941 instances, 47 unique instances\n",
      "  Science: 3009693 instances, 61 unique instances\n",
      "  Computing: 1936829 instances, 39 unique instances\n",
      "  Global Perspectives: 879439 instances, 18 unique instances\n",
      "  Digital Literacy: 791753 instances, 16 unique instances\n",
      "***************\n",
      "Stage 5:\n",
      "  English: 5567043 instances, 93 unique instances\n",
      "  Mathematics: 3027414 instances, 52 unique instances\n",
      "  Science: 3304350 instances, 56 unique instances\n",
      "  Computing: 2423190 instances, 40 unique instances\n",
      "  Digital Literacy: 909483 instances, 15 unique instances\n",
      "***************\n",
      "Stage 6:\n",
      "  English: 6467370 instances, 94 unique instances\n",
      "  Mathematics: 3680705 instances, 55 unique instances\n",
      "  Science: 3803275 instances, 57 unique instances\n",
      "  Computing: 2710960 instances, 40 unique instances\n",
      "  Humanities: 5659850 instances, 82 unique instances\n",
      "  Global Perspectives: 1225700 instances, 18 unique instances\n",
      "  Digital Literacy: 1110340 instances, 16 unique instances\n",
      "***************\n",
      "Stage 7:\n",
      "  Mathematics: 4631052 instances, 63 unique instances\n",
      "  Science: 5303548 instances, 72 unique instances\n",
      "  Computing: 3022411 instances, 42 unique instances\n",
      "  Digital Literacy: 1031670 instances, 14 unique instances\n",
      "  English: 5173634 instances, 70 unique instances\n",
      "***************\n",
      "Stage 8:\n",
      "  Mathematics: 4310592 instances, 61 unique instances\n",
      "  Science: 5120712 instances, 70 unique instances\n",
      "  Computing: 3176424 instances, 43 unique instances\n",
      "  Digital Literacy: 1096488 instances, 15 unique instances\n",
      "  Global Perspectives: 1341408 instances, 18 unique instances\n",
      "  English: 5260128 instances, 71 unique instances\n",
      "***************\n",
      "Stage 9:\n",
      "  Mathematics: 3300150 instances, 55 unique instances\n",
      "  Science: 4236764 instances, 70 unique instances\n",
      "  Computing: 2658978 instances, 45 unique instances\n",
      "  Digital Literacy: 914613 instances, 15 unique instances\n",
      "  Global Perspectives: 1112622 instances, 18 unique instances\n",
      "  Humanities: 4840220 instances, 79 unique instances\n",
      "  English: 4114187 instances, 67 unique instances\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "skill_dict = {}\n",
    "for i in tqdm(seed_data):\n",
    "    if i not in skill_dict:\n",
    "        skill_dict[i] = {}\n",
    "    for j in seed_data[i]['context']:\n",
    "        if j['skill'] not in skill_dict[i]:\n",
    "            skill_dict[i][j['skill']] = []\n",
    "        skill_dict[i][j['skill']].append(j['id'])\n",
    "\n",
    "for stage in skill_dict:\n",
    "    print(f\"Stage {stage}:\")\n",
    "    for skill in skill_dict[stage]:\n",
    "        print(f\"  {skill}: {len(skill_dict[stage][skill])} instances, {len(set(skill_dict[stage][skill]))} unique instances\")\n",
    "        skill_dict[stage][skill] = list(set(skill_dict[stage][skill]))\n",
    "    print(\"***************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d89e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0:\n",
      "  Language and Communication: 443373 instances, 24 unique instances\n",
      "  Literacy: 423507 instances, 20 unique instances\n",
      "  Mathematics Development: 459627 instances, 26 unique instances\n",
      "  Scientific Reasoning: 317856 instances, 18 unique instances\n",
      "  Perceptual, Motor, and Physical Development: 282639 instances, 17 unique instances\n",
      "  Approaches to Learning: 742266 instances, 41 unique instances\n",
      "  Social and Emotional Development: 651063 instances, 36 unique instances\n",
      "***************\n",
      "Stage 1:\n",
      "  English: 1712064 instances, 90 unique instances\n",
      "  Mathematics: 700828 instances, 37 unique instances\n",
      "  Science: 681548 instances, 37 unique instances\n",
      "  Computing: 508028 instances, 28 unique instances\n",
      "  Global Perspectives: 315228 instances, 18 unique instances\n",
      "  Digital Literacy: 202440 instances, 11 unique instances\n",
      "***************\n",
      "Stage 2:\n",
      "  English: 2623698 instances, 99 unique instances\n",
      "  Mathematics: 1226610 instances, 48 unique instances\n",
      "  Science: 1124046 instances, 42 unique instances\n",
      "  Computing: 878724 instances, 31 unique instances\n",
      "  Global Perspectives: 480942 instances, 18 unique instances\n",
      "  Digital Literacy: 334026 instances, 13 unique instances\n",
      "***************\n",
      "Stage 3:\n",
      "  English: 3714282 instances, 102 unique instances\n",
      "  Mathematics: 1816243 instances, 53 unique instances\n",
      "  Science: 1704703 instances, 49 unique instances\n",
      "  Computing: 1349634 instances, 36 unique instances\n",
      "  Humanities: 2699268 instances, 75 unique instances\n",
      "  Digital Literacy: 479622 instances, 14 unique instances\n",
      "***************\n",
      "Stage 4:\n",
      "  English: 5173474 instances, 106 unique instances\n",
      "  Mathematics: 2230835 instances, 47 unique instances\n",
      "  Science: 3069010 instances, 61 unique instances\n",
      "  Computing: 2230835 instances, 39 unique instances\n",
      "  Global Perspectives: 856228 instances, 18 unique instances\n",
      "  Digital Literacy: 750489 instances, 16 unique instances\n",
      "***************\n",
      "Stage 5:\n",
      "  English: 5538720 instances, 93 unique instances\n",
      "  Mathematics: 2995944 instances, 52 unique instances\n",
      "  Science: 3332673 instances, 56 unique instances\n",
      "  Computing: 2426337 instances, 40 unique instances\n",
      "  Digital Literacy: 893748 instances, 15 unique instances\n",
      "***************\n",
      "Stage 6:\n",
      "  English: 6362825 instances, 94 unique instances\n",
      "  Mathematics: 3691520 instances, 55 unique instances\n",
      "  Science: 3929450 instances, 57 unique instances\n",
      "  Computing: 2757825 instances, 40 unique instances\n",
      "  Humanities: 5576935 instances, 82 unique instances\n",
      "  Global Perspectives: 1204070 instances, 18 unique instances\n",
      "  Digital Literacy: 1103130 instances, 16 unique instances\n",
      "***************\n",
      "Stage 7:\n",
      "  Mathematics: 4497317 instances, 63 unique instances\n",
      "  Science: 5276801 instances, 72 unique instances\n",
      "  Computing: 3091189 instances, 42 unique instances\n",
      "  Digital Literacy: 997281 instances, 14 unique instances\n",
      "  English: 5116319 instances, 70 unique instances\n",
      "***************\n",
      "Stage 8:\n",
      "  Mathematics: 4325664 instances, 61 unique instances\n",
      "  Science: 5143320 instances, 70 unique instances\n",
      "  Computing: 3074688 instances, 43 unique instances\n",
      "  Digital Literacy: 1100256 instances, 15 unique instances\n",
      "  Global Perspectives: 1292424 instances, 18 unique instances\n",
      "  English: 5154624 instances, 71 unique instances\n",
      "***************\n",
      "Stage 9:\n",
      "  Mathematics: 3215289 instances, 55 unique instances\n",
      "  Science: 4224192 instances, 70 unique instances\n",
      "  Computing: 2662121 instances, 45 unique instances\n",
      "  Digital Literacy: 939757 instances, 15 unique instances\n",
      "  Global Perspectives: 1084335 instances, 18 unique instances\n",
      "  Humanities: 4909366 instances, 79 unique instances\n",
      "  English: 3988467 instances, 67 unique instances\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "skill_dict = {}\n",
    "for i in tqdm(seed_data):\n",
    "    if i not in skill_dict:\n",
    "        skill_dict[i] = {}\n",
    "    for j in seed_data[i]['instruct']:\n",
    "        if j['skill'] not in skill_dict[i]:\n",
    "            skill_dict[i][j['skill']] = []\n",
    "        skill_dict[i][j['skill']].append(j['id'])\n",
    "\n",
    "for stage in skill_dict:\n",
    "    print(f\"Stage {stage}:\")\n",
    "    for skill in skill_dict[stage]:\n",
    "        print(f\"  {skill}: {len(skill_dict[stage][skill])} instances, {len(set(skill_dict[stage][skill]))} unique instances\")\n",
    "        skill_dict[stage][skill] = list(set(skill_dict[stage][skill]))\n",
    "    print(\"***************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a117872",
   "metadata": {},
   "source": [
    "### Random 1000 for prompt checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "479f4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save random 1000 samples for each stage\n",
    "seed_data_sample = {}\n",
    "for i in range(10):\n",
    "    seed_data_sample[i] = {\"context\": [], \"instruct\": []}\n",
    "for i in range(10):\n",
    "    seed_data_sample[i]['context'] = random.sample(seed_data[i]['context'], 1000)\n",
    "    seed_data_sample[i]['instruct'] = random.sample(seed_data[i]['instruct'], 1000)\n",
    "for i in range(10):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/instruct/random_1000.jsonl\", \"w\") as f:\n",
    "        json.dump(seed_data_sample[i]['instruct'], f, indent=4)\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{i}/seed/context/random_1000.jsonl\", \"w\") as f:\n",
    "        json.dump(seed_data_sample[i]['context'], f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db1402",
   "metadata": {},
   "source": [
    "### Stage 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ee39ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 11\n",
    "stage = 0\n",
    "type = \"context\"\n",
    "chunk_size = len(seed_data[stage][type]) // num_gpus\n",
    "chunks = [seed_data[stage][type][i:i + chunk_size] for i in range(0, len(seed_data[stage][type]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/chunk_{i}.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/metadata_chunks.jsonl\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bcddd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3006990, 12, 273362)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_data[stage][type]), len(chunks), chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65d0a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 19\n",
    "stage = 0\n",
    "type = \"instruct\"\n",
    "chunk_size = len(seed_data[stage][type]) // num_gpus\n",
    "chunks = [seed_data[stage][type][i:i + chunk_size] for i in range(0, len(seed_data[stage][type]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/chunk_{i}.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/metadata_chunks.jsonl\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d609b8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3320331, 20, 174754)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_data[stage][type]), len(chunks), chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b036975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\n",
      "\n",
      "Your task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. Skill Alignment:\n",
      "   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\n",
      "   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\n",
      "   - The response should mimic the complexity of the language used by a child of that age group and stage.\n",
      "\n",
      "2. Using the Word, Part-of-speech tuple:\n",
      "   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\n",
      "   - Expand the word into a topic relevant to the skill and age group.\n",
      "   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\n",
      "   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\n",
      "\n",
      "3. Language Style:\n",
      "   - Keep vocabulary simple and concrete, matching the given age group and stage.\n",
      "\n",
      "4. Output Format:\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate an instruction based on the topic, targeting the skill/indicator.\n",
      "- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction_response_prompts = {\n",
    "    \"system\": \"You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\\n\\nYour task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. Skill Alignment:\\n   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\\n   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\\n   - The response should mimic the complexity of the language used by a child of that age group and stage.\\n\\n2. Using the Word, Part-of-speech tuple:\\n   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\\n   - Expand the word into a topic relevant to the skill and age group.\\n   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\\n   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\\n\\n3. Language Style:\\n   - Keep vocabulary simple and concrete, matching the given age group and stage.\\n\\n4. Output Format:\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate an instruction based on the topic, targeting the skill/indicator.\\n- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(instruction_response_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(instruction_response_prompts['user'])\n",
    "type = \"instruct\"\n",
    "stage = 0\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt.json\", \"w\") as f:\n",
    "    json.dump(instruction_response_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f84403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\n",
      "\n",
      "Your task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. Skill Alignment:\n",
      "   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\n",
      "   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\n",
      "   - The response should mimic the complexity of the language used by a child of that age group and stage.\n",
      "\n",
      "2. Using the Word, Part-of-speech tuple:\n",
      "   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\n",
      "   - Expand the word into a topic relevant to the skill and age group.\n",
      "   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\n",
      "   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\n",
      "\n",
      "3. Language Style:\n",
      "   - Keep vocabulary simple and concrete, matching the given age group and stage.\n",
      "\n",
      "4. Output Format:\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate an instruction based on the topic, targeting the skill/indicator.\n",
      "- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction_response_prompts = {\n",
    "    \"system\": \"You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\\n\\nYour task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. Skill Alignment:\\n   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\\n   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\\n   - The response should mimic the complexity of the language used by a child of that age group and stage.\\n\\n2. Using the Word, Part-of-speech tuple:\\n   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\\n   - Expand the word into a topic relevant to the skill and age group.\\n   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\\n   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\\n\\n3. Language Style:\\n   - Keep vocabulary simple and concrete, matching the given age group and stage.\\n\\n4. Output Format:\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate an instruction based on the topic, targeting the skill/indicator.\\n- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(instruction_response_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(instruction_response_prompts['user'])\n",
    "type = \"instruct\"\n",
    "stage = 0\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt.json\", \"w\") as f:\n",
    "    json.dump(instruction_response_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9321a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in early childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and a 5-year-old child, based on early learning indicators and goals.\n",
      "\n",
      "You will be given a dictionary with the following fields:\n",
      "indicator: A specific developmental behavior or learning objective the child should demonstrate.\n",
      "skill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\n",
      "subskill: A narrower focus within the skill.\n",
      "goal: The learning goal for the child.\n",
      "age_group: Always 0–5.\n",
      "stage: A developmental stage (typically 0).\n",
      "Text Type Template: A short phrase describing the activity type or context (e.g., \"Compare size/quantity\", \"Take turns\", \"Retell a story\").\n",
      "word_list: A word (and its part of speech) that must serve as a general inspiration for the exchange (e.g., [\"bee\", \"Noun\"] or [\"run\", \"Verb\"]). This word does not need to appear verbatim in the dialogue.\n",
      "\n",
      "Your task is to:\n",
      "1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\n",
      "2. Write a natural-sounding 5-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\n",
      "3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \"pretends to flip a switch\".\n",
      "4. Do not use any italic, bold, or markdown styling (*like this*).\n",
      "5. Use the word_list only as a soft prompt for variety – it is not required to appear in the final text.\n",
      "6. Do not include irrelevant or excessive character details (e.g., “Leo is friendly” or unrelated anecdotes).\n",
      "7. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 5-year-old might say.\n",
      "8. Avoid meta-language or explanations. Just produce the conversational pair.\n",
      "\n",
      "Note:\n",
      "-   Entire exchange should utilize only text based cues - no pictures, physical objects or sensory materials\n",
      "-   The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 5 year old could reasonably have\n",
      "-   Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \"I like red more\" is fine, \"red is better than yellow\" is not, unless justified in the prompt)\n",
      "-   Always use the word to generate the instruction-response pairs.\n",
      "-   Acceptable responses may include:\n",
      "    -   Facts stated or implied by the prompt\n",
      "    -   Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce)\n",
      "    -   Personal experiences that are common for children (e.g. \"I felt happy when I played with my ball\")\n",
      "-   Avoid:\n",
      "    -   Imaginary details that require visuals or unspecified context to verify (e.g., \"the red bee is faster than the yellow bee\")\n",
      "    -   Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\n",
      "    -   Descriptions of non-verbal actions, such as \"nods\", \"smiles\", or \"runs in place\".\n",
      "\n",
      "Strictly follow the Output Format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- word_list: {word_list}\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "new_ins = {\"system\": \"You are an expert in early childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and a 5-year-old child, based on early learning indicators and goals.\\n\\nYou will be given a dictionary with the following fields:\\nindicator: A specific developmental behavior or learning objective the child should demonstrate.\\nskill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\\nsubskill: A narrower focus within the skill.\\ngoal: The learning goal for the child.\\nage_group: Always 0–5.\\nstage: A developmental stage (typically 0).\\nText Type Template: A short phrase describing the activity type or context (e.g., \\\"Compare size/quantity\\\", \\\"Take turns\\\", \\\"Retell a story\\\").\\nword_list: A word (and its part of speech) that must serve as a general inspiration for the exchange (e.g., [\\\"bee\\\", \\\"Noun\\\"] or [\\\"run\\\", \\\"Verb\\\"]). This word does not need to appear verbatim in the dialogue.\\n\\nYour task is to:\\n1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\\n2. Write a natural-sounding 5-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\\n3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \\\"pretends to flip a switch\\\".\\n4. Do not use any italic, bold, or markdown styling (*like this*).\\n5. Use the word_list only as a soft prompt for variety – it is not required to appear in the final text.\\n6. Do not include irrelevant or excessive character details (e.g., “Leo is friendly” or unrelated anecdotes).\\n7. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 5-year-old might say.\\n8. Avoid meta-language or explanations. Just produce the conversational pair.\\n\\nNote:\\n-   Entire exchange should utilize only text based cues - no pictures, physical objects or sensory materials\\n-   The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 5 year old could reasonably have\\n-   Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \\\"I like red more\\\" is fine, \\\"red is better than yellow\\\" is not, unless justified in the prompt)\\n-   Always use the word to generate the instruction-response pairs.\\n-   Acceptable responses may include:\\n    -   Facts stated or implied by the prompt\\n    -   Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce)\\n    -   Personal experiences that are common for children (e.g. \\\"I felt happy when I played with my ball\\\")\\n-   Avoid:\\n    -   Imaginary details that require visuals or unspecified context to verify (e.g., \\\"the red bee is faster than the yellow bee\\\")\\n    -   Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\\n    -   Descriptions of non-verbal actions, such as \\\"nods\\\", \\\"smiles\\\", or \\\"runs in place\\\".\\n\\nStrictly follow the Output Format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "\"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- word_list: {word_list}\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"}\n",
    "\n",
    "print(new_ins['system'])\n",
    "print(\"____________________________________\")\n",
    "print(new_ins['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d48cff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"instruct\"\n",
    "stage = 0\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt_v3.json\", \"w\") as f:\n",
    "    json.dump(new_ins, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7af632c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in early childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and a 5-year-old child, based on early learning indicators and goals.\n",
      "\n",
      "You will be given a dictionary with the following fields:\n",
      "indicator: A specific developmental behavior or learning objective the child should demonstrate.\n",
      "skill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\n",
      "subskill: A narrower focus within the skill.\n",
      "goal: The learning goal for the child.\n",
      "age_group: Always 0–5.\n",
      "stage: A developmental stage (typically 0).\n",
      "Text Type Template: A short phrase describing the activity type or context (e.g., \"Compare size/quantity\", \"Take turns\", \"Retell a story\").\n",
      "word_list: A word (and its part of speech) that must clearly inspire the topic, imagery, or situation used in the exchange (e.g., [\"bee\", \"Noun\"] should lead to an interaction involving bees, even if the word \"bee\" itself is not spoken).\n",
      "\n",
      "Your task is to:\n",
      "1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\n",
      "2. Write a natural-sounding 5-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\n",
      "3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \"pretends to flip a switch\".\n",
      "4. Do not use any italic, bold, or markdown styling (*like this*).\n",
      "5. The word_list must meaningfully inspire the setting, situation, or imagery of the exchange, even if the word is not used exactly.\n",
      "6. Do not include irrelevant or excessive character details (e.g., “Leo is friendly” or unrelated anecdotes).\n",
      "7. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 5-year-old might say.\n",
      "8. Avoid meta-language or explanations. Just produce the conversational pair.\n",
      "\n",
      "Note:\n",
      "-   Entire exchange should utilize only text based cues - no pictures, physical objects or sensory materials\n",
      "-   The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 5 year old could reasonably have\n",
      "-   Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \"I like red more\" is fine, \"red is better than yellow\" is not, unless justified in the prompt)\n",
      "-   Acceptable responses may include:\n",
      "    -   Facts stated or implied by the prompt\n",
      "    -   Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce)\n",
      "    -   Personal experiences that are common for children (e.g. \"I felt happy when I played with my ball\")\n",
      "-   Avoid:\n",
      "    -   Imaginary details that require visuals or unspecified context to verify (e.g., \"the red bee is faster than the yellow bee\")\n",
      "    -   Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\n",
      "    -   Descriptions of non-verbal actions, such as \"nods\", \"smiles\", or \"runs in place\".\n",
      "\n",
      "Strictly follow the Output Format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- word_list: {word_list}\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "new_ins = {\n",
    "    \"system\": \"You are an expert in early childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and a 5-year-old child, based on early learning indicators and goals.\\n\\nYou will be given a dictionary with the following fields:\\nindicator: A specific developmental behavior or learning objective the child should demonstrate.\\nskill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\\nsubskill: A narrower focus within the skill.\\ngoal: The learning goal for the child.\\nage_group: Always 0–5.\\nstage: A developmental stage (typically 0).\\nText Type Template: A short phrase describing the activity type or context (e.g., \\\"Compare size/quantity\\\", \\\"Take turns\\\", \\\"Retell a story\\\").\\nword_list: A word (and its part of speech) that must clearly inspire the topic, imagery, or situation used in the exchange (e.g., [\\\"bee\\\", \\\"Noun\\\"] should lead to an interaction involving bees, even if the word \\\"bee\\\" itself is not spoken).\\n\\nYour task is to:\\n1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\\n2. Write a natural-sounding 5-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\\n3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \\\"pretends to flip a switch\\\".\\n4. Do not use any italic, bold, or markdown styling (*like this*).\\n5. The word_list must meaningfully inspire the setting, situation, or imagery of the exchange, even if the word is not used exactly.\\n6. Do not include irrelevant or excessive character details (e.g., “Leo is friendly” or unrelated anecdotes).\\n7. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 5-year-old might say.\\n8. Avoid meta-language or explanations. Just produce the conversational pair.\\n\\nNote:\\n-   Entire exchange should utilize only text based cues - no pictures, physical objects or sensory materials\\n-   The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 5 year old could reasonably have\\n-   Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \\\"I like red more\\\" is fine, \\\"red is better than yellow\\\" is not, unless justified in the prompt)\\n-   Acceptable responses may include:\\n    -   Facts stated or implied by the prompt\\n    -   Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce)\\n    -   Personal experiences that are common for children (e.g. \\\"I felt happy when I played with my ball\\\")\\n-   Avoid:\\n    -   Imaginary details that require visuals or unspecified context to verify (e.g., \\\"the red bee is faster than the yellow bee\\\")\\n    -   Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\\n    -   Descriptions of non-verbal actions, such as \\\"nods\\\", \\\"smiles\\\", or \\\"runs in place\\\".\\n\\nStrictly follow the Output Format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- word_list: {word_list}\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(new_ins['system'])\n",
    "print(\"____________________________________\")\n",
    "print(new_ins['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1482fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"instruct\"\n",
    "stage = 0\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt_v4.json\", \"w\") as f:\n",
    "    json.dump(new_ins, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8d9fac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in early childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and a 5-year-old child, based on early learning indicators and goals.\n",
      "\n",
      "You will be given a dictionary with the following fields:\n",
      "- indicator: A specific developmental behavior or learning objective the child should demonstrate.\n",
      "- skill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\n",
      "- subskill: A narrower focus within the skill.\n",
      "- goal: The learning goal for the child.\n",
      "- age_group: Always 0–5.\n",
      "- stage: A developmental stage (typically 0).\n",
      "- context_template: A short phrase describing the activity type or context (e.g., \"Compare size/quantity\", \"Take turns\", \"Retell a story\").\n",
      "- word_list: A word (and its part of speech) that must serve as a general inspiration for the exchange (e.g., [\"bee\", \"Noun\"] or [\"run\", \"Verb\"]). This word does not need to appear verbatim in the dialogue, but should meaningfully inspire the prompt or response.\n",
      "\n",
      "Your task is to:\n",
      "1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\n",
      "2. Write a natural-sounding 5-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\n",
      "3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \"pretends to flip a switch\".\n",
      "4. Do not use any italic, bold, or markdown styling (*like this*).\n",
      "5. Use the word_list as a soft prompt – it must meaningfully influence either the instruction or response (but not necessarily appear verbatim).\n",
      "6. Do not start all prompts with \"Imagine...\" – vary your phrasing. Use imagination only where natural, not by default.\n",
      "7. Avoid assumptions about prior events. If a task involves recalling something (e.g., \"What happened yesterday?\"), include that information in the prompt. Do not assume past events unless explicitly described.\n",
      "8. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 5-year-old might say.\n",
      "9. Avoid meta-language or explanations. Just produce the conversational pair.\n",
      "\n",
      "Note:\n",
      "- Entire exchange should utilize only text-based cues – no pictures, physical objects, or sensory materials.\n",
      "- The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 5-year-old could reasonably have.\n",
      "- Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \"I like red more\" is fine, \"red is better than yellow\" is not, unless justified in the prompt).\n",
      "\n",
      "Acceptable responses may include:\n",
      "- Facts stated or implied by the prompt.\n",
      "- Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce).\n",
      "- Personal experiences that are common for children (e.g., \"I felt happy when I played with my ball\").\n",
      "\n",
      "Avoid:\n",
      "- Imaginary details that require visuals or unspecified context to verify (e.g., \"the red bee is faster than the yellow bee\").\n",
      "- Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\n",
      "- Descriptions of non-verbal actions, such as \"nods\", \"smiles\", or \"runs in place\".\n",
      "\n",
      "Strictly follow the Output Format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- word_list: {word_list}\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "new_ins = {\n",
    "    \"system\": \"You are an expert in early childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and a 5-year-old child, based on early learning indicators and goals.\\n\\nYou will be given a dictionary with the following fields:\\n- indicator: A specific developmental behavior or learning objective the child should demonstrate.\\n- skill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\\n- subskill: A narrower focus within the skill.\\n- goal: The learning goal for the child.\\n- age_group: Always 0–5.\\n- stage: A developmental stage (typically 0).\\n- context_template: A short phrase describing the activity type or context (e.g., \\\"Compare size/quantity\\\", \\\"Take turns\\\", \\\"Retell a story\\\").\\n- word_list: A word (and its part of speech) that must serve as a general inspiration for the exchange (e.g., [\\\"bee\\\", \\\"Noun\\\"] or [\\\"run\\\", \\\"Verb\\\"]). This word does not need to appear verbatim in the dialogue, but should meaningfully inspire the prompt or response.\\n\\nYour task is to:\\n1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\\n2. Write a natural-sounding 5-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\\n3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \\\"pretends to flip a switch\\\".\\n4. Do not use any italic, bold, or markdown styling (*like this*).\\n5. Use the word_list as a soft prompt – it must meaningfully influence either the instruction or response (but not necessarily appear verbatim).\\n6. Do not start all prompts with \\\"Imagine...\\\" – vary your phrasing. Use imagination only where natural, not by default.\\n7. Avoid assumptions about prior events. If a task involves recalling something (e.g., \\\"What happened yesterday?\\\"), include that information in the prompt. Do not assume past events unless explicitly described.\\n8. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 5-year-old might say.\\n9. Avoid meta-language or explanations. Just produce the conversational pair.\\n\\nNote:\\n- Entire exchange should utilize only text-based cues – no pictures, physical objects, or sensory materials.\\n- The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 5-year-old could reasonably have.\\n- Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \\\"I like red more\\\" is fine, \\\"red is better than yellow\\\" is not, unless justified in the prompt).\\n\\nAcceptable responses may include:\\n- Facts stated or implied by the prompt.\\n- Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce).\\n- Personal experiences that are common for children (e.g., \\\"I felt happy when I played with my ball\\\").\\n\\nAvoid:\\n- Imaginary details that require visuals or unspecified context to verify (e.g., \\\"the red bee is faster than the yellow bee\\\").\\n- Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\\n- Descriptions of non-verbal actions, such as \\\"nods\\\", \\\"smiles\\\", or \\\"runs in place\\\".\\n\\nStrictly follow the Output Format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- word_list: {word_list}\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(new_ins['system'])\n",
    "print(\"____________________________________\")\n",
    "print(new_ins['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2d82fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"instruct\"\n",
    "stage = 0\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt_v5.json\", \"w\") as f:\n",
    "    json.dump(new_ins, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "103163fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in early childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and a 5-year-old child, based on early learning indicators and goals.\n",
      "\n",
      "You will be given a dictionary with the following fields:\n",
      "- indicator: A specific developmental behavior or learning objective the child should demonstrate.\n",
      "- skill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\n",
      "- subskill: A narrower focus within the skill.\n",
      "- goal: The learning goal for the child.\n",
      "- age_group: Always 0–5.\n",
      "- stage: A developmental stage (typically 0).\n",
      "- context_template: A short phrase describing the activity type or context (e.g., \"Compare size/quantity\", \"Take turns\", \"Retell a story\").\n",
      "- word_list: A word (and its part of speech) that must always serve as a general inspiration for the exchange (e.g., [\"bee\", \"Noun\"] or [\"run\", \"Verb\"]). This must meaningfully inspire the prompt or response.\n",
      "\n",
      "Your task is to:\n",
      "1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\n",
      "2. Write a natural-sounding 5-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\n",
      "3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \"pretends to flip a switch\".\n",
      "4. Do not use any italic, bold, or markdown styling (*like this*).\n",
      "5. Use the word_list as a soft prompt – it must always meaningfully influence the topic of the dialogue (but not necessarily appear verbatim).\n",
      "6. Do not start all prompts with \"Imagine...\" – vary your phrasing. Use imagination only where natural, not by default.\n",
      "7. Avoid assumptions about prior events. If a task involves recalling something (e.g., \"What happened yesterday?\"), include that information in the instruction. Do not assume past events unless explicitly described.\n",
      "8. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 5-year-old might say.\n",
      "9. Avoid meta-language or explanations. Just produce the conversational pair.\n",
      "\n",
      "Note:\n",
      "- Entire exchange should utilize only text-based cues – no pictures, physical objects, or sensory materials.\n",
      "- The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 5-year-old could reasonably have.\n",
      "- Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \"I like red more\" is fine, \"red is better than yellow\" is not, unless justified in the prompt).\n",
      "\n",
      "Acceptable responses may include:\n",
      "- Facts stated or implied by the prompt.\n",
      "- Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce).\n",
      "- Personal experiences that are common for children (e.g., \"I felt happy when I played with my ball\").\n",
      "\n",
      "Avoid:\n",
      "- Imaginary details that require visuals or unspecified context to verify (e.g., \"the red bee is faster than the yellow bee\").\n",
      "- Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\n",
      "- Descriptions of non-verbal actions, such as \"nods\", \"smiles\", or \"runs in place\".\n",
      "\n",
      "Strictly follow the Output Format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- word_list: {word_list}\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "new_ins = {\n",
    "    \"system\": \"You are an expert in early childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and a 5-year-old child, based on early learning indicators and goals.\\n\\nYou will be given a dictionary with the following fields:\\n- indicator: A specific developmental behavior or learning objective the child should demonstrate.\\n- skill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\\n- subskill: A narrower focus within the skill.\\n- goal: The learning goal for the child.\\n- age_group: Always 0–5.\\n- stage: A developmental stage (typically 0).\\n- context_template: A short phrase describing the activity type or context (e.g., \\\"Compare size/quantity\\\", \\\"Take turns\\\", \\\"Retell a story\\\").\\n- word_list: A word (and its part of speech) that must always serve as a general inspiration for the exchange (e.g., [\\\"bee\\\", \\\"Noun\\\"] or [\\\"run\\\", \\\"Verb\\\"]). This must meaningfully inspire the prompt or response.\\n\\nYour task is to:\\n1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\\n2. Write a natural-sounding 5-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\\n3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \\\"pretends to flip a switch\\\".\\n4. Do not use any italic, bold, or markdown styling (*like this*).\\n5. Use the word_list as a soft prompt – it must always meaningfully influence the topic of the dialogue (but not necessarily appear verbatim).\\n6. Do not start all prompts with \\\"Imagine...\\\" – vary your phrasing. Use imagination only where natural, not by default.\\n7. Avoid assumptions about prior events. If a task involves recalling something (e.g., \\\"What happened yesterday?\\\"), include that information in the instruction. Do not assume past events unless explicitly described.\\n8. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 5-year-old might say.\\n9. Avoid meta-language or explanations. Just produce the conversational pair.\\n\\nNote:\\n- Entire exchange should utilize only text-based cues – no pictures, physical objects, or sensory materials.\\n- The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 5-year-old could reasonably have.\\n- Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \\\"I like red more\\\" is fine, \\\"red is better than yellow\\\" is not, unless justified in the prompt).\\n\\nAcceptable responses may include:\\n- Facts stated or implied by the prompt.\\n- Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce).\\n- Personal experiences that are common for children (e.g., \\\"I felt happy when I played with my ball\\\").\\n\\nAvoid:\\n- Imaginary details that require visuals or unspecified context to verify (e.g., \\\"the red bee is faster than the yellow bee\\\").\\n- Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\\n- Descriptions of non-verbal actions, such as \\\"nods\\\", \\\"smiles\\\", or \\\"runs in place\\\".\\n\\nStrictly follow the Output Format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- word_list: {word_list}\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(new_ins['system'])\n",
    "print(\"____________________________________\")\n",
    "print(new_ins['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a399119",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"instruct\"\n",
    "stage = 0\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt_v6.json\", \"w\") as f:\n",
    "    json.dump(new_ins, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40027dc",
   "metadata": {},
   "source": [
    "### Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d0d3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 9\n",
    "stage = 1\n",
    "type = \"context\"\n",
    "chunk_size = len(seed_data[stage][type]) // num_gpus\n",
    "chunks = [seed_data[stage][type][i:i + chunk_size] for i in range(0, len(seed_data[stage][type]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/chunk_{i}.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/metadata_chunks.jsonl\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0547179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4038196, 10, 448688)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_data[stage][type]), len(chunks), chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b98c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 11\n",
    "stage = 1\n",
    "type = \"instruct\"\n",
    "chunk_size = len(seed_data[stage][type]) // num_gpus\n",
    "chunks = [seed_data[stage][type][i:i + chunk_size] for i in range(0, len(seed_data[stage][type]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/chunk_{i}.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/metadata_chunks.jsonl\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9445948b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4120136, 12, 374557)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_data[stage][type]), len(chunks), chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbe4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\n",
      "\n",
      "Your task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. **Context Generation:**\n",
      "   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\n",
      "   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\n",
      "   - Expand the selected word into a more detailed, skill-aligned topic.\n",
      "   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\n",
      "   - The generated text should be **between 250 and 500 words**.\n",
      "   - The text must clearly align with the skill, subskill, goal, and indicator.\n",
      "   - The selected word does not need to explicitly appear in the final text.\n",
      "\n",
      "2. **Writing Style:**\n",
      "   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\n",
      "   - Include actions, feelings, interactions, and details to make the text rich and lively.\n",
      "   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\n",
      "\n",
      "3. **Output Format:** Strictly return the output in the following JSON structure:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n",
      "Only output the JSON. No additional commentary.\n",
      "____________________________________\n",
      "Generate a rich and engaging context text based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate a detailed text of **250–500 words** following the context template.\n",
      "- Enrich the text with actions, emotions, and interactions.\n",
      "\n",
      "Output strictly in this format:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "simple_context_prompts = {\n",
    "    \"system\": \"You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\\n\\nYour task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. **Context Generation:**\\n   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\\n   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\\n   - Expand the selected word into a more detailed, skill-aligned topic.\\n   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\\n   - The generated text should be **between 250 and 500 words**.\\n   - The text must clearly align with the skill, subskill, goal, and indicator.\\n   - The selected word does not need to explicitly appear in the final text.\\n\\n2. **Writing Style:**\\n   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\\n   - Include actions, feelings, interactions, and details to make the text rich and lively.\\n   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\\n\\n3. **Output Format:** Strictly return the output in the following JSON structure:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\\nOnly output the JSON. No additional commentary.\",\n",
    "    \"user\": \"Generate a rich and engaging context text based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate a detailed text of **250–500 words** following the context template.\\n- Enrich the text with actions, emotions, and interactions.\\n\\nOutput strictly in this format:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(simple_context_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(simple_context_prompts['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9496f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt.json\", \"w\") as f:\n",
    "    json.dump(simple_context_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74ad0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\n",
      "\n",
      "Your task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. Skill Alignment:\n",
      "   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\n",
      "   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\n",
      "   - The response should mimic the complexity of the language used by a child of that age group and stage.\n",
      "\n",
      "2. Using the Word, Part-of-speech tuple:\n",
      "   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\n",
      "   - Expand the word into a topic relevant to the skill and age group.\n",
      "   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\n",
      "   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\n",
      "\n",
      "3. Language Style:\n",
      "   - Keep vocabulary simple and concrete, matching the given age group and stage.\n",
      "\n",
      "4. Output Format:\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate an instruction based on the topic, targeting the skill/indicator.\n",
      "- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction_response_prompts = {\n",
    "    \"system\": \"You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\\n\\nYour task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. Skill Alignment:\\n   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\\n   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\\n   - The response should mimic the complexity of the language used by a child of that age group and stage.\\n\\n2. Using the Word, Part-of-speech tuple:\\n   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\\n   - Expand the word into a topic relevant to the skill and age group.\\n   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\\n   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\\n\\n3. Language Style:\\n   - Keep vocabulary simple and concrete, matching the given age group and stage.\\n\\n4. Output Format:\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate an instruction based on the topic, targeting the skill/indicator.\\n- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(instruction_response_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(instruction_response_prompts['user'])\n",
    "type = \"instruct\"\n",
    "stage = 1\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt.json\", \"w\") as f:\n",
    "    json.dump(instruction_response_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8261c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in childhood education and developmental psychology. Your task is to generate realistic instruction–response pairs between a teacher and an early elementary aged child (6 years old or stage 1 of 5-11 years old), based on early learning indicators and goals.\n",
      "\n",
      "You will be given a dictionary with the following fields:\n",
      "- indicator: A specific developmental behavior or learning objective the child should demonstrate.\n",
      "- skill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\n",
      "- subskill: A narrower focus within the skill.\n",
      "- goal: The learning goal for the child.\n",
      "- age_group: Always 5-11.\n",
      "- stage: A developmental stage (typically 1).\n",
      "- context_template: A short phrase describing the activity type or context (e.g., \"Compare size/quantity\", \"Take turns\", \"Retell a story\").\n",
      "- word_list: A word (and its part of speech) that must always serve as a general inspiration for the exchange (e.g., [\"bee\", \"Noun\"] or [\"run\", \"Verb\"]). This must meaningfully inspire the prompt or response.\n",
      "\n",
      "Your task is to:\n",
      "1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\n",
      "2. Write a natural-sounding 6-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\n",
      "3. The entire exchange must be purely verbal – do not reference physical objects, gestures, or actions such as \"pretends to flip a switch\".\n",
      "4. Do not use any italic, bold, or markdown styling (*like this*).\n",
      "5. Use the word_list as a soft prompt – it must always meaningfully influence the topic of the dialogue (but not necessarily appear verbatim).\n",
      "6. Do not start all prompts with \"Imagine...\" – vary your phrasing. Use imagination only where natural, not by default.\n",
      "7. Avoid assumptions about prior events. If a task involves recalling something (e.g., \"What happened yesterday?\"), include that information in the instruction. Do not assume past events unless explicitly described.\n",
      "8. Use developmentally appropriate language, tone, and sentence length. The child’s answer should sound like something a real 6-year-old might say.\n",
      "9. Avoid meta-language or explanations. Just produce the conversational pair.\n",
      "\n",
      "Note:\n",
      "- Entire exchange should utilize only text-based cues – no pictures, physical objects, or sensory materials.\n",
      "- The child’s response should be plausible and verifiable based on either the text given or common world knowledge that a 6-year-old could reasonably have.\n",
      "- Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \"I like red more\" is fine, \"red is better than yellow\" is not, unless justified in the prompt).\n",
      "\n",
      "Acceptable responses may include:\n",
      "- Facts stated or implied by the prompt.\n",
      "- Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce).\n",
      "- Personal experiences that are common for children (e.g., \"I felt happy when I played with my ball\").\n",
      "\n",
      "Avoid:\n",
      "- Imaginary details that require visuals or unspecified context to verify (e.g., \"the red bee is faster than the yellow bee\").\n",
      "- Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\n",
      "- Descriptions of non-verbal actions, such as \"nods\", \"smiles\", or \"runs in place\".\n",
      "\n",
      "Strictly follow the Output Format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- word_list: {word_list}\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "new_ins = {\n",
    "    \"system\": \"You are an expert in childhood education and developmental psychology. Your task is to generate realistic instruction\\u2013response pairs between a teacher and an early elementary aged child (6 years old or stage 1 of 5-11 years old), based on early learning indicators and goals.\\n\\nYou will be given a dictionary with the following fields:\\n- indicator: A specific developmental behavior or learning objective the child should demonstrate.\\n- skill: The broader area of development (e.g., Social-Emotional, Language, Scientific Reasoning).\\n- subskill: A narrower focus within the skill.\\n- goal: The learning goal for the child.\\n- age_group: Always 5-11.\\n- stage: A developmental stage (typically 1).\\n- context_template: A short phrase describing the activity type or context (e.g., \\\"Compare size/quantity\\\", \\\"Take turns\\\", \\\"Retell a story\\\").\\n- word_list: A word (and its part of speech) that must always serve as a general inspiration for the exchange (e.g., [\\\"bee\\\", \\\"Noun\\\"] or [\\\"run\\\", \\\"Verb\\\"]). This must meaningfully inspire the prompt or response.\\n\\nYour task is to:\\n1. Write a short teacher prompt that invites the child to think, reflect, observe, express, or act in a way that helps them demonstrate the given indicator.\\n2. Write a natural-sounding 6-year-old child response that clearly shows the child demonstrating the indicator, goal, and skill through words.\\n3. The entire exchange must be purely verbal \\u2013 do not reference physical objects, gestures, or actions such as \\\"pretends to flip a switch\\\".\\n4. Do not use any italic, bold, or markdown styling (*like this*).\\n5. Use the word_list as a soft prompt \\u2013 it must always meaningfully influence the topic of the dialogue (but not necessarily appear verbatim).\\n6. Do not start all prompts with \\\"Imagine...\\\" \\u2013 vary your phrasing. Use imagination only where natural, not by default.\\n7. Avoid assumptions about prior events. If a task involves recalling something (e.g., \\\"What happened yesterday?\\\"), include that information in the instruction. Do not assume past events unless explicitly described.\\n8. Use developmentally appropriate language, tone, and sentence length. The child\\u2019s answer should sound like something a real 6-year-old might say.\\n9. Avoid meta-language or explanations. Just produce the conversational pair.\\n\\nNote:\\n- Entire exchange should utilize only text-based cues \\u2013 no pictures, physical objects, or sensory materials.\\n- The child\\u2019s response should be plausible and verifiable based on either the text given or common world knowledge that a 6-year-old could reasonably have.\\n- Avoid responses that make arbitrary or subjective claims unless they reflect typical personal experiences (e.g., \\\"I like red more\\\" is fine, \\\"red is better than yellow\\\" is not, unless justified in the prompt).\\n\\nAcceptable responses may include:\\n- Facts stated or implied by the prompt.\\n- Inferences from general child-level world knowledge (e.g., waves break sandcastles, bees fly, a ball can bounce).\\n- Personal experiences that are common for children (e.g., \\\"I felt happy when I played with my ball\\\").\\n\\nAvoid:\\n- Imaginary details that require visuals or unspecified context to verify (e.g., \\\"the red bee is faster than the yellow bee\\\").\\n- Fantastical or inconsistent events unless the prompt clearly allows or invites storytelling.\\n- Descriptions of non-verbal actions, such as \\\"nods\\\", \\\"smiles\\\", or \\\"runs in place\\\".\\n\\nStrictly follow the Output Format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- word_list: {word_list}\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(new_ins['system'])\n",
    "print(\"____________________________________\")\n",
    "print(new_ins['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0774fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"instruct\"\n",
    "stage = 1\n",
    "import json\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/{type}/prompt_v1.json\", \"w\") as f:\n",
    "    json.dump(new_ins, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc18a4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#dnn4\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage1/seed/instruct/chunk_0.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/ins/chunk_0.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage1/seed/instruct/chunk_1.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/ins/chunk_1.jsonl -t 1.0\n",
    "#dnn3\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage1/seed/instruct/chunk_2.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/ins/chunk_2.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage1/seed/instruct/chunk_3.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/ins/chunk_3.jsonl -t 1.0\n",
    "#octovc\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/chunk_4.jsonl -o /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/raw/instruct/chunk_4.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/chunk_5.jsonl -o /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/raw/instruct/chunk_5.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=4,5 python general_generation.py -p /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/chunk_6.jsonl -o /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/raw/instruct/chunk_6.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=6,7 python general_generation.py -p /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/chunk_7.jsonl -o /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/raw/instruct/chunk_7.jsonl -t 1.0\n",
    "#4a100\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/2f3ba0f218724c749be90a644b6b4033/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /scratch/azureml/cr/j/2f3ba0f218724c749be90a644b6b4033/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/chunk_8.jsonl -o /scratch/azureml/cr/j/2f3ba0f218724c749be90a644b6b4033/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/raw/instruct/chunk_8.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /scratch/azureml/cr/j/2f3ba0f218724c749be90a644b6b4033/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /scratch/azureml/cr/j/2f3ba0f218724c749be90a644b6b4033/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/chunk_9.jsonl -o /scratch/azureml/cr/j/2f3ba0f218724c749be90a644b6b4033/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/raw/instruct/chunk_9.jsonl -t 1.0\n",
    "#2a100s\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/c55299a810684176805f69ce4d35795f/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/prompt_v1.json -s /scratch/azureml/cr/j/c55299a810684176805f69ce4d35795f/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/seed/instruct/chunk_10.jsonl -o /scratch/azureml/cr/j/c55299a810684176805f69ce4d35795f/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage1/raw/instruct/chunk_10.jsonl -t 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1273c7",
   "metadata": {},
   "source": [
    "### Stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 6\n",
    "stage = 2\n",
    "chunk_size = len(seed_data_c[stage]) // num_gpus\n",
    "chunks = [seed_data_c[stage][i:i + chunk_size] for i in range(0, len(seed_data_c[stage]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/context/c_{i}_seed.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/context/c_seed_metadata.json\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53bd8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 6\n",
    "stage = 2\n",
    "chunk_size = len(seed_data_ins[stage]) // num_gpus\n",
    "chunks = [seed_data_ins[stage][i:i + chunk_size] for i in range(0, len(seed_data_ins[stage]), chunk_size)]\n",
    "chunk_metadata = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/instruct/ins_{i}_seed.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f)\n",
    "    chunk_metadata[f\"c_{i}\"] = {\n",
    "        \"start\": i * chunk_size,\n",
    "        \"end\": (i + 1) * chunk_size,\n",
    "        \"size\": len(chunk)\n",
    "    }\n",
    "with open(f\"/datadrive/pavan/az_storage/data_unorganized/stages/stage{stage}/seed/instruct/ins_seed_metadata.json\", \"w\") as f:\n",
    "    json.dump(chunk_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cce14a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#dnn4 (working)\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/chunk_0.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/ins/chunk_0.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/chunk_1.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/ins/chunk_1.jsonl -t 1.0\n",
    "#dnn3 (working)\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/chunk_2.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/ins/chunk_2.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/chunk_3.jsonl -o /datadrive/pavan/CurLL/data/temp_stages/ins/chunk_3.jsonl -t 1.0\n",
    "#quickdevvc (do again) -- got destroyed\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_4.jsonl -o /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_4.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_5.jsonl -o /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_5.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=4,5 python general_generation.py -p /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_6.jsonl -o /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_6.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=6,7 python general_generation.py -p /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_7.jsonl -o /scratch/azureml/cr/j/ef717686936a41448973873b81f1a807/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_7.jsonl -t 1.0\n",
    "#octovc1 (working)\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_8.jsonl -o /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_8.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_9.jsonl -o /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_9.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=4,5 python general_generation.py -p /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_10.jsonl -o /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_10.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=6,7 python general_generation.py -p /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_11.jsonl -o /scratch/azureml/cr/j/4b1df45904d0482bb3c3b778f6ce12ff/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_11.jsonl -t 1.0\n",
    "#octovc2 (do again) -- not able to run inference\n",
    "CUDA_VISIBLE_DEVICES=0,1 python general_generation.py -p /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_12.jsonl -o /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_12.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=2,3 python general_generation.py -p /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_13.jsonl -o /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_13.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=4,5 python general_generation.py -p /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_14.jsonl -o /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_14.jsonl -t 1.0\n",
    "CUDA_VISIBLE_DEVICES=6,7 python general_generation.py -p /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/prompt_v6.json -s /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/seed/instruct/chunk_15.jsonl -o /scratch/azureml/cr/j/baf9810c2cc14bbaa8b98056b303e9e3/cap/data-capability/wd/INPUT_asdf/data_unorganized/stages/stage0/raw/instruct/chunk_15.jsonl -t 1.0\n",
    "#2a100s (working)\n",
    "#4a100s (working)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490f6a5",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "755f299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\n",
      "\n",
      "Your task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. **Context Generation:**\n",
      "   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\n",
      "   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\n",
      "   - Expand the selected word into a more detailed, skill-aligned topic.\n",
      "   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\n",
      "   - The generated text should be **between 250 and 500 words**.\n",
      "   - The text must clearly align with the skill, subskill, goal, and indicator.\n",
      "   - The selected word does not need to explicitly appear in the final text.\n",
      "\n",
      "2. **Writing Style:**\n",
      "   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\n",
      "   - Include actions, feelings, interactions, and details to make the text rich and lively.\n",
      "   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\n",
      "\n",
      "3. **Output Format:** Strictly return the output in the following JSON structure:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n",
      "Only output the JSON. No additional commentary.\n",
      "____________________________________\n",
      "Generate a rich and engaging context text based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate a detailed text of **250–500 words** following the context template.\n",
      "- Enrich the text with actions, emotions, and interactions.\n",
      "\n",
      "Output strictly in this format:\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"generated_text\": \"<generated text between 250 and 500 words>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "simple_context_prompts = {\n",
    "    \"system\": \"You are an AI model generating training data to help language models simulate human developmental skills at various stages (especially for early childhood development).\\n\\nYour task is to create simple, engaging texts based on provided developmental indicators, skills, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. **Context Generation:**\\n   - Use the provided word and its part of speech to create a meaningful, developmentally appropriate topic.\\n   - **Ensure the selected word and expanded topic fit the required Text Type Template (context_template).**\\n   - Expand the selected word into a more detailed, skill-aligned topic.\\n   - Generate a rich, complete, and engaging text matching the provided context template (e.g., narrative retelling, descriptive explanation).\\n   - The generated text should be **between 250 and 500 words**.\\n   - The text must clearly align with the skill, subskill, goal, and indicator.\\n   - The selected word does not need to explicitly appear in the final text.\\n\\n2. **Writing Style:**\\n   - Use simple vocabulary and sentence structures appropriate for the developmental stage.\\n   - Include actions, feelings, interactions, and details to make the text rich and lively.\\n   - Avoid overly abstract or culturally specific references unless appropriate for the age group.\\n\\n3. **Output Format:** Strictly return the output in the following JSON structure:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\\nOnly output the JSON. No additional commentary.\",\n",
    "    \"user\": \"Generate a rich and engaging context text based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate a detailed text of **250–500 words** following the context template.\\n- Enrich the text with actions, emotions, and interactions.\\n\\nOutput strictly in this format:\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"generated_text\\\": \\\"<generated text between 250 and 500 words>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(simple_context_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(simple_context_prompts['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71763aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/context/prompt.json\", \"w\") as f:\n",
    "    json.dump(simple_context_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae084dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\n",
      "\n",
      "Your task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\n",
      "\n",
      "Guidelines:\n",
      "\n",
      "1. Skill Alignment:\n",
      "   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\n",
      "   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\n",
      "   - The response should not pretend to be a child; it should simply model the appropriate behavior.\n",
      "\n",
      "2. Using the Word, Part-of-speech tuple:\n",
      "   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\n",
      "   - Expand the word into a topic relevant to the skill and age group.\n",
      "   - Neither the instruction nor the response must explicitly use the word, but the context should logically connect to it.\n",
      "\n",
      "3. Language Style:\n",
      "   - Keep vocabulary simple and concrete, matching the given age group and stage.\n",
      "   - Instructions should feel natural and actionable for the developmental level, even if a model is responding.\n",
      "\n",
      "4. Output Format:\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the word into a skill-relevant topic.\n",
      "- Generate an instruction based on the topic, targeting the skill/indicator.\n",
      "- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction_response_prompts = {\n",
    "    \"system\": \"You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\\n\\nYour task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\\n\\nGuidelines:\\n\\n1. Skill Alignment:\\n   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\\n   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\\n   - The response should not pretend to be a child; it should simply model the appropriate behavior.\\n\\n2. Using the Word, Part-of-speech tuple:\\n   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\\n   - Expand the word into a topic relevant to the skill and age group.\\n   - Neither the instruction nor the response must explicitly use the word, but the context should logically connect to it.\\n\\n3. Language Style:\\n   - Keep vocabulary simple and concrete, matching the given age group and stage.\\n   - Instructions should feel natural and actionable for the developmental level, even if a model is responding.\\n\\n4. Output Format:\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the word into a skill-relevant topic.\\n- Generate an instruction based on the topic, targeting the skill/indicator.\\n- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(instruction_response_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(instruction_response_prompts['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c257d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/stages/stage0/seed/instruct/prompt.json\", \"w\") as f:\n",
    "    json.dump(instruction_response_prompts, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ebe9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbd4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'selected_word': 'rainstorm', 'selected_word_pos': 'Noun', 'expanded_topic': 'Discussing a loud and startling weather event', 'instruction': \"I'm telling you about the big storm we had last night. It was very loud, and there were bright flashes. What do you think about that?\", 'response': 'Oh wow! That sounds... surprising. I think I would want to be close to someone if I heard that.'}, 'id': 'i0', 'indicator': 'Uses verbal and non-verbal signals appropriately to acknowledge the comments or questions of others.', 'skill': 'Language and Communication', 'subskill': 'Attending and Understanding', 'goal': 'Child attends to communication and language from others.', 'age_group': '0-5', 'stage': 0, 'context_template': 'Describe feeling outcomes', 'word_list': [['scared', 'Adjective'], ['guy', 'Noun'], ['rainstorm', 'Noun'], ['cake', 'Noun'], ['jelly', 'Noun'], ['library', 'Noun'], ['lightning', 'Noun'], ['whisper', 'Verb'], ['walk', 'Verb'], ['cheer', 'Verb']]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"/datadrive/pavan/CurLL/data/raw/instruct/ins_0_seed.jsonl\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae2efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:  I'm telling you about the dog I saw at the park. He was very fluffy and brown! What color did I say the dog was?\n",
      "Response:  Brown!\n"
     ]
    }
   ],
   "source": [
    "i = 100\n",
    "print(\"Instruction: \", data[i]['output'][\"instruction\"])\n",
    "print(\"Response: \", data[i]['output'][\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": 1,
   "id": "44bc93a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\n",
      "\n",
      "Your task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\n",
      "\n",
      "Strictly follow these guidelines:\n",
      "\n",
      "1. Skill Alignment:\n",
      "   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\n",
      "   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\n",
      "   - The response should mimic the complexity of the language used by a child of that age group and stage.\n",
      "\n",
      "2. Using the Word, Part-of-speech tuple:\n",
      "   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\n",
      "   - Expand the word into a topic relevant to the skill and age group.\n",
      "   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\n",
      "   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\n",
      "\n",
      "3. Language Style:\n",
      "   - Keep vocabulary simple and concrete, matching the given age group and stage.\n",
      "\n",
      "4. Output Format:\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n",
      "\n",
      "Do not add any commentary or explanations. Only output the JSON.\n",
      "____________________________________\n",
      "Generate an instruction-response pair based on the following input:\n",
      "\n",
      "- id: {id}\n",
      "- Indicator: {indicator}\n",
      "- Skill: {skill}\n",
      "- Sub-skill: {subskill}\n",
      "- Goal: {goal}\n",
      "- Age Group: {age_group}\n",
      "- Stage: {stage}\n",
      "- Text Type Template: {context_template}\n",
      "- (Word, Part of speech): {word_list}\n",
      "\n",
      "Instructions:\n",
      "- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\n",
      "- Generate an instruction based on the topic, targeting the skill/indicator.\n",
      "- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\n",
      "\n",
      "Output strictly in this format:\n",
      "\n",
      "```json\n",
      "{{\n",
      "    \"expanded_topic\": \"<expanded topic>\",\n",
      "    \"instruction\": \"<instruction>\",\n",
      "    \"response\": \"<response>\"\n",
      "}}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instruction_response_prompts = {\n",
    "    \"system\": \"You are an AI model generating training instruction-response pairs to help language models simulate human developmental skills across different stages.\\n\\nYour task is to create high-quality instruction-response pairs based on a provided developmental indicator, skill, and a tuple of word and its part of speech.\\n\\nStrictly follow these guidelines:\\n\\n1. Skill Alignment:\\n   - The instruction must be a realistic situation that directly invites the model to demonstrate the specified skill and indicator.\\n   - The response must fully demonstrate the expected behavior according to the skill and indicator, in a simple and clear way.\\n   - The response should mimic the complexity of the language used by a child of that age group and stage.\\n\\n2. Using the Word, Part-of-speech tuple:\\n   - Use the word and its part of speech tag to build a realistic, developmentally appropriate situation.\\n   - Expand the word into a topic relevant to the skill and age group.\\n   - Ensure the selected word and expanded topic fit the required Text Type Template (instruct_template).\\n   - Neither the instruction nor the response need not use the word, but the context should logically connect to it.\\n\\n3. Language Style:\\n   - Keep vocabulary simple and concrete, matching the given age group and stage.\\n\\n4. Output Format:\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\\n\\nDo not add any commentary or explanations. Only output the JSON.\",\n",
    "    \"user\": \"Generate an instruction-response pair based on the following input:\\n\\n- id: {id}\\n- Indicator: {indicator}\\n- Skill: {skill}\\n- Sub-skill: {subskill}\\n- Goal: {goal}\\n- Age Group: {age_group}\\n- Stage: {stage}\\n- Text Type Template: {context_template}\\n- (Word, Part of speech): {word_list}\\n\\nInstructions:\\n- Expand the selected word into a skill-relevant topic **that fits the Text Type Template**.\\n- Generate an instruction based on the topic, targeting the skill/indicator.\\n- Generate a response that demonstrates correct behavior aligned with the skill/indicator.\\n\\nOutput strictly in this format:\\n\\n```json\\n{{\\n    \\\"expanded_topic\\\": \\\"<expanded topic>\\\",\\n    \\\"instruction\\\": \\\"<instruction>\\\",\\n    \\\"response\\\": \\\"<response>\\\"\\n}}\\n```\"\n",
    "}\n",
    "print(instruction_response_prompts['system'])\n",
    "print(\"____________________________________\")\n",
    "print(instruction_response_prompts['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0ddd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
