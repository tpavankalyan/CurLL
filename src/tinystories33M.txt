
🔍 Loading model and tokenizer for 'roneneldan/TinyStories-33M'...

🔢 Parameter Breakdown
----------------------
Embedding parameters:     40,170,240
Non-embedding parameters: 28,343,808
Total parameters:         68,514,048

⚙️ Model Config Info
--------------------
Model class: GPTNeoModel
Architectures: ['GPTNeoForCausalLM']
Hidden size: 768
Intermediate size: None
Num hidden layers: 4
Num attention heads: 16
Max position embeddings: 2048
Tied embeddings: True
Is encoder: False
Is decoder-only: False

🔤 Tokenizer Info
-----------------
Tokenizer class: GPT2TokenizerFast
Vocab size: 50,257
Special tokens:
  pad_token   : None
  bos_token   : '<|endoftext|>'
  eos_token   : '<|endoftext|>'
  unk_token   : '<|endoftext|>'
  cls_token   : None
  sep_token   : None
  mask_token  : None
